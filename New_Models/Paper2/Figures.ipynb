{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (1850306633.py, line 44)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[1], line 44\u001b[0;36m\u001b[0m\n\u001b[0;31m    \u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m incomplete input\n"
     ]
    }
   ],
   "source": [
    "'''Figures showing UQ for impact site'''\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from GPR import *\n",
    "\n",
    "\n",
    "\n",
    "'''plots the prediction in red, and plots the '''\n",
    "def plot_impact_site_with_uncertainty(x_pred, x_std, y_pred, y_std, x_true, y_true, saving_path=None):\n",
    "    #material basis vectors for RPA bone\n",
    "    Material_X = np.array([-0.87491124, -0.44839274,  0.18295974])\n",
    "    Material_Y = np.array([ 0.23213791, -0.71986519, -0.65414532])\n",
    "    Material_Z = np.array([ 0.42502036, -0.5298472,   0.7339071 ])\n",
    "    #Center of mass of the RPA bone in abaqus basis\n",
    "    CM = np.array([106.55,72.79,56.64])\n",
    "    # #Ossification center of the RPA bone in abaqus basis\n",
    "    OC = np.array([130.395996,46.6063,98.649696])\n",
    "    \n",
    "    parietal_node_location_df = pd.read_csv('/Users/jakehirst/Desktop/sfx/sfx_ML_code/sfx_ML/Feature_gathering/parital_node_locations.csv')\n",
    "    RPA_x = parietal_node_location_df['RPA nodes x']; RPA_y = parietal_node_location_df['RPA nodes y']; RPA_z = parietal_node_location_df['RPA nodes z']\n",
    "    \n",
    "    #converting the RPA node locations into Jimmy's reference frame\n",
    "    RPA_x, RPA_y, RPA_z = convert_coordinates_to_new_basis(Material_X, Material_Y, Material_Z, CM, RPA_x, RPA_y, RPA_z)\n",
    "    \n",
    "    #loading previously trained models\n",
    "    # model_x = load_GPR_model(f'/Users/jakehirst/Desktop/model_results/MODEL_COMPARISONS/GPR_{labels_to_predict[0]}/GPR_model_fold{models_fold_to_pull[labels_to_predict[0]]}.sav')\n",
    "    # model_y = load_GPR_model(f'/Users/jakehirst/Desktop/model_results/MODEL_COMPARISONS/GPR_{labels_to_predict[1]}/GPR_model_fold{models_fold_to_pull[labels_to_predict[1]]}.sav')\n",
    "    # model_z = load_GPR_model(f'/Users/jakehirst/Desktop/model_results/GPR_{labels_to_predict[2]}/GPR_model_fold{models_fold_to_pull[labels_to_predict[2]]}.sav')\n",
    "    \n",
    "    #predicting with previously trained models  \n",
    "    # x_predictions, x_stds = model_x.predict(full_dataset[all_important_features[labels_to_predict[0]]].to_numpy(), return_std=True)\n",
    "    # y_predictions, y_stds = model_y.predict(full_dataset[all_important_features[labels_to_predict[1]]].to_numpy(), return_std=True)\n",
    "    # z_predictions, z_stds = model_z.predict(remove_ABAQUS_features(full_dataset[all_important_features[labels_to_predict[2]]]).to_numpy(), return_std=True)\n",
    "    \n",
    "    # x_true = full_dataset[labels_to_predict[0]].to_numpy()\n",
    "    # y_true = full_dataset[labels_to_predict[1]].to_numpy()\n",
    "    # z_true = full_dataset['impact site z'].to_numpy()\n",
    "    \n",
    "    '''3d plot of RPA nodes and the predicted x, y and z values in '''\n",
    "    # Create a 3D figure\n",
    "    fig = plt.figure(figsize=(10,8))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    ax.grid(False)\n",
    "    \n",
    "    ax.scatter(RPA_z, RPA_x, RPA_y, c='grey', alpha=0.025)\n",
    "    # x_dist = np.random.normal(x_predictions[i], x_stds[i], 100)\n",
    "    # y_dist = np.random.normal(y_predictions[i], y_stds[i], 100)\n",
    "    x_dist = np.random.normal(x_pred, x_std, 100)\n",
    "    y_dist = np.random.normal(y_pred, y_std, 100)\n",
    "    \n",
    "    point_size = 50\n",
    "    \n",
    "    z_val=15\n",
    "    z_dist = np.random.normal(z_val, 3, 5000) #TODO find a good value for z\n",
    "    ax.scatter(z_dist, x_dist, y_dist, c='cyan', alpha=0.01)\n",
    "    ax.scatter(z_val, x_pred, y_pred, c='blue', label='Mean predicted impact location', s=point_size)\n",
    "    ax.scatter(z_val, x_true, y_true, c='orange', label='True impact location', s=point_size)\n",
    "    \n",
    "\n",
    "    ax.set_xlabel('Z')\n",
    "    ax.set_ylabel('X')\n",
    "    ax.set_zlabel('Y')\n",
    "    ax.set_xlim3d(-60, 60)\n",
    "    ax.set_ylim3d(-80, 80)\n",
    "    ax.set_zlim3d(-60, 60)\n",
    "    ax.set_title('GPR prediction for impact site in right parietal bone', fontweight='bold')\n",
    "    ax.legend()\n",
    "    \n",
    "    normal_vector = np.array([0,1,0])\n",
    "    # Calculate the azimuthal and polar angles\n",
    "    azimuth = np.arctan2(normal_vector[1], normal_vector[0])\n",
    "    polar = np.arccos(normal_vector[2])\n",
    "    # Convert angles to degrees\n",
    "    azimuth = np.degrees(azimuth)\n",
    "    polar = np.degrees(polar)\n",
    "    # # Set the camera direction using the angles (customizing a bit)\n",
    "    ax.view_init(elev=-5, azim=azimuth + 270)\n",
    "    # # Show the plot\n",
    "    if(saving_path == None):\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.savefig(saving_path)\n",
    "    plt.close()\n",
    "    return\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model_types = ['Single RF', 'RF fed GPR']\n",
    "fold = 1\n",
    "\n",
    "# parietal_nodes_folder = ''\n",
    "\n",
    "for model_type in model_types:\n",
    "    for fold in range(1,6):\n",
    "        x_model_folder = f'/Volumes/Jake_ssd/Paper 2/without_transformations/UQ_bagging_models_without_transformations/impact site x/{model_type}'\n",
    "        y_model_folder = f'/Volumes/Jake_ssd/Paper 2/without_transformations/UQ_bagging_models_without_transformations/impact site y/{model_type}'\n",
    "\n",
    "        #defining folders to get the models and to store the results\n",
    "        model_saving_folder = f'{model_folder}/{label_to_predict}/{model_type}/{num_models}_models/fold_{fold_no}'\n",
    "        results_saving_folder = f'{results_folder}/{label_to_predict}/{model_type}/{num_models}_models/fold_{fold_no}'\n",
    "        \n",
    "        #defining folders where the datasets are coming from (5-fold cv)\n",
    "        test_features_path = Paper2_path + f'/5fold_datasets/{label_to_predict}/fold{fold_no}/test_features.csv'\n",
    "        test_labels_path = Paper2_path + f'/5fold_datasets/{label_to_predict}/fold{fold_no}/test_labels.csv'\n",
    "        train_features_path = Paper2_path + f'/5fold_datasets/{label_to_predict}/fold{fold_no}/train_features.csv'\n",
    "        train_labels_path = Paper2_path + f'/5fold_datasets/{label_to_predict}/fold{fold_no}/train_labels.csv'\n",
    "\n",
    "        #defining the features that each model used (since they vary with each model)\n",
    "        features_to_keep = ????\n",
    "        \n",
    "        if(model_type in ['ANN', 'RF', 'GPR','ridge']):\n",
    "            #defining folders to get the models and to store the results\n",
    "            model_saving_folder = f'{model_folder}/{label_to_predict}/{model_type}/{num_models}_models/fold_{fold_no}'\n",
    "            results_saving_folder = f'{results_folder}/{label_to_predict}/{model_type}/{num_models}_models/fold_{fold_no}'\n",
    "            #predicting the test and train sets with the bagging models\n",
    "            test_r2, test_ensemble_predictions, test_uncertanties, test_labels = Get_predictions_and_uncertainty_with_bagging(test_features_path, test_labels_path, model_saving_folder, results_saving_folder, features_to_keep, label_to_predict, model_type)\n",
    "            train_r2, train_ensemble_predictions, train_uncertanties, train_labels = Get_predictions_and_uncertainty_with_bagging(train_features_path, train_labels_path, model_saving_folder, results_saving_folder, features_to_keep, label_to_predict, model_type)\n",
    "        else:\n",
    "            #defining folders to get the models and to store the results\n",
    "            model_saving_folder = f'{model_folder}/{label_to_predict}/{model_type}/1_models/fold_{fold_no}'\n",
    "            results_saving_folder = f'{results_folder}/{label_to_predict}/{model_type}/1_models/fold_{fold_no}'\n",
    "            #predicting the test and train sets with the NON bagging models\n",
    "            test_r2, test_ensemble_predictions, test_uncertanties, test_labels = Get_predictions_and_uncertainty(test_features_path, test_labels_path, model_saving_folder, results_saving_folder, features_to_keep, label_to_predict, model_type)\n",
    "            train_r2, train_ensemble_predictions, train_uncertanties, train_labels = Get_predictions_and_uncertainty(train_features_path, train_labels_path, model_saving_folder, results_saving_folder, features_to_keep, label_to_predict, model_type)\n",
    "\n",
    "\n",
    "\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
