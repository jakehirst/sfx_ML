{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''plot sharpness vs R2 before and after recalibration'''\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import r2_score\n",
    "'''hi'''\n",
    "\n",
    "# Load the Excel sheet\n",
    "file_path = '/Users/jakehirst/Desktop/sfx/Presentations_and_Papers/Paper 2/results table.xlsx'\n",
    "df_impact_site_x = pd.read_excel(file_path, sheet_name='impact site x')\n",
    "df_impact_site_y = pd.read_excel(file_path, sheet_name='impact site y')\n",
    "df_height = pd.read_excel(file_path, sheet_name='height')\n",
    "\n",
    "'''\n",
    "plots the sharpness vs R2 before and after recalibration\n",
    "'''\n",
    "def plot_sharpness_vs_R2(df, label_to_predict):\n",
    "    # Extracting data\n",
    "    sharpness_precal = df['Sharpness']\n",
    "    sharpness_postcal = df['Sharpness post-cal']\n",
    "    r2 = df['Test R^2']\n",
    "\n",
    "    # Sorting the r2 and sharpness values according to r2\n",
    "    idx = np.argsort(r2)\n",
    "    r2_sorted = r2[idx]\n",
    "    sharpness_precal_sorted = sharpness_precal[idx]\n",
    "    sharpness_postcal_sorted = sharpness_postcal[idx]\n",
    "    \n",
    "    # Fit lines to sorted data\n",
    "    slope_precal, intercept_precal = np.polyfit(r2_sorted, sharpness_precal_sorted, 1)\n",
    "    slope_postcal, intercept_postcal = np.polyfit(r2_sorted, sharpness_postcal_sorted, 1)\n",
    "\n",
    "    # Generate values for the linear fit lines\n",
    "    fit_line_precal = slope_precal * r2_sorted + intercept_precal\n",
    "    fit_line_postcal = slope_postcal * r2_sorted + intercept_postcal\n",
    "\n",
    "    # Calculate R^2 values using r2_score\n",
    "    precal_r2_score = r2_score(sharpness_precal_sorted, fit_line_precal)\n",
    "    postcal_r2_score = r2_score(sharpness_postcal_sorted, fit_line_postcal)\n",
    "    print(sharpness_postcal_sorted)\n",
    "    print(fit_line_postcal)\n",
    "    \n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.scatter(r2_sorted, sharpness_precal_sorted, marker='*', c='blue', label='Pre-cal')\n",
    "    plt.scatter(r2_sorted, sharpness_postcal_sorted, c='red', label='Post-cal')\n",
    "    \n",
    "    #Plot linear fit lines with R^2 in the label\n",
    "    plt.plot(r2_sorted, fit_line_precal, 'b--')  # Blue dashed line with R^2\n",
    "    plt.plot(r2_sorted, fit_line_postcal, 'r--')  # Red dashed line with R^2\n",
    "    \n",
    "    if(label_to_predict == 'height'):\n",
    "        plt.xlim((0.0,0.3))\n",
    "    elif(label_to_predict == 'impact site x'):\n",
    "        plt.xlim((0.6, 0.9))\n",
    "    elif(label_to_predict == 'impact site y'):\n",
    "        plt.xlim((0.5, 0.8))\n",
    "    plt.title(label_to_predict, fontweight=\"bold\")\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.xlabel('R\\u00B2')\n",
    "    plt.ylabel('Sharpness')\n",
    "    # plt.show()\n",
    "    \n",
    "    plt.savefig(f'/Users/jakehirst/Desktop/sfx/Presentations_and_Papers/Paper 2/Figures/sharpness_before_after_recal_{label_to_predict}.pdf', format='pdf', dpi=300)\n",
    "\n",
    "    plt.close()\n",
    "\n",
    "    \n",
    "    return\n",
    "\n",
    "plot_sharpness_vs_R2(df_impact_site_x, 'Impact site x')\n",
    "plot_sharpness_vs_R2(df_impact_site_y, 'Impact site y')\n",
    "plot_sharpness_vs_R2(df_height, 'Height')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''making figures from the results table'''\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Load the Excel sheet\n",
    "file_path = '/Users/jakehirst/Desktop/sfx/Presentations_and_Papers/Paper 2/results table.xlsx'\n",
    "df_impact_site_x = pd.read_excel(file_path, sheet_name='impact site x')\n",
    "df_impact_site_y = pd.read_excel(file_path, sheet_name='impact site y')\n",
    "df_height = pd.read_excel(file_path, sheet_name='height')\n",
    "\n",
    "def plot_metrics(label, df):\n",
    "    # Colors for the original and post-cal metrics\n",
    "    colors = {\n",
    "        'Miscal area': 'lightorange',\n",
    "        'Miscal area post-cal': 'darkorange',\n",
    "        'Sharpness': 'lightblue',\n",
    "        'Sharpness post-cal': 'darkblue',\n",
    "        'Dispersion': 'lightgreen',\n",
    "        'Dispersion post-cal': 'darkgreen'\n",
    "    }\n",
    "\n",
    "    # Spacing between each model type\n",
    "    group_width = 0.8  # the total width of the group of bars for each model type\n",
    "    bar_width = group_width / len(colors)  # the width of each individual bar within the group\n",
    "    space_width = 0.2  # the width of the space between groups\n",
    "\n",
    "    # Calculate the positions of the groups and the bars within each group\n",
    "    num_models = len(df)\n",
    "    total_width = (group_width + space_width) * num_models\n",
    "    index = pd.np.linspace(0, total_width - group_width - space_width, num_models)\n",
    "\n",
    "    # Set up the figure and axes\n",
    "    fig, ax = plt.subplots(figsize=(14, 8))\n",
    "\n",
    "    # Function to plot bars for a metric\n",
    "    def plot_bars(metric, color, offset):\n",
    "        if(metric == 'Sharpness'):\n",
    "            original = df[metric] /10\n",
    "            post_cal = df[f'{metric} post-cal'] /10\n",
    "            ax.bar(index + offset, original, bar_width, label=f'{metric} Original (\\u00f710)', color=color)\n",
    "            ax.bar(index + offset + bar_width, post_cal, bar_width, label=f'{metric} Post-Cal (\\u00f710)', color=f'dark{color}')\n",
    "\n",
    "        else:\n",
    "            original = df[metric]\n",
    "            post_cal = df[f'{metric} post-cal']\n",
    "            ax.bar(index + offset, original, bar_width, label=f'{metric} Original', color=color)\n",
    "            ax.bar(index + offset + bar_width, post_cal, bar_width, label=f'{metric} Post-Cal', color=f'dark{color}')\n",
    "\n",
    "    # Plot bars for each metric with its respective color\n",
    "    plot_bars('Miscal area', 'orange', 0)\n",
    "    plot_bars('Sharpness', 'blue', bar_width * 2)\n",
    "    plot_bars('Dispersion', 'green', bar_width * 4)\n",
    "\n",
    "    # Set the x-axis labels, title, and x-axis ticks\n",
    "    ax.set_xlabel('Model Type')\n",
    "    ax.set_title('Comparison of Original and Post-Calibration Metrics by Model Type')\n",
    "    ax.set_xticks(index + group_width / 2)\n",
    "    ax.set_xticklabels(df['Model type'], rotation=45, ha=\"right\")\n",
    "\n",
    "    # Adding the legend\n",
    "    ax.legend()\n",
    "\n",
    "    # Show the plot\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_metrics('impact site x', df_impact_site_x)\n",
    "plot_metrics('impact site y', df_impact_site_y)\n",
    "plot_metrics('height', df_height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Figures import *\n",
    "from ReCalibration import *\n",
    "\n",
    "all_labels = ['height', 'phi', 'theta', \n",
    "                            'impact site x', 'impact site y', 'impact site z', \n",
    "                            'impact site r', 'impact site phi', 'impact site theta']\n",
    "\n",
    "model_types = ['Single RF']\n",
    "model_types = ['RF_fed_GPR']\n",
    "model_types = ['ANN', 'GPR', 'RF', 'ridge', 'Single RF', 'Single GPR', 'NN_fed_GPR', 'NN_fed_RF', 'RF_fed_GPR']\n",
    "model_types = ['Single RF']\n",
    "\n",
    "# parietal_nodes_folder = ''\n",
    "for fold_no in range(1,2):\n",
    "    for model_type in model_types:\n",
    "        x_model_folder = f'/Volumes/Jake_ssd/Paper 2/without_transformations/UQ_bagging_models_without_transformations/impact site x/{model_type}'\n",
    "        y_model_folder = f'/Volumes/Jake_ssd/Paper 2/without_transformations/UQ_bagging_models_without_transformations/impact site y/{model_type}'\n",
    "\n",
    "        #defining folders to get the models and to store the results\n",
    "        # model_saving_folder = f'{model_folder}/{label_to_predict}/{model_type}/{num_models}_models/fold_{fold_no}'\n",
    "        results_saving_folder = None\n",
    "        \n",
    "        Paper2_path = f'/Volumes/Jake_ssd/Paper 2/without_transformations'\n",
    "        #defining folders where the datasets are coming from (5-fold cv)\n",
    "        x_test_features_path = Paper2_path + f'/5fold_datasets/impact site x/fold{fold_no}/test_features.csv'\n",
    "        x_test_labels_path = Paper2_path + f'/5fold_datasets/impact site x/fold{fold_no}/test_labels.csv'\n",
    "        y_test_features_path = Paper2_path + f'/5fold_datasets/impact site y/fold{fold_no}/test_features.csv'\n",
    "        y_test_labels_path = Paper2_path + f'/5fold_datasets/impact site y/fold{fold_no}/test_labels.csv'\n",
    "\n",
    "\n",
    "        #defining the features that each model used (since they vary with each model)\n",
    "        # features_to_keep = ????\n",
    "        df = pd.read_csv(x_test_features_path, index_col=0)\n",
    "        all_features = df.columns\n",
    "        # all_features = all_features.drop(all_labels)\n",
    "        features_to_keep = str(all_features.drop('timestep_init').to_list())\n",
    "        \n",
    "        if(model_type in ['ANN', 'RF', 'GPR','ridge']):\n",
    "            #predicting the test and train sets with the bagging models\n",
    "            test_r2_X, test_ensemble_predictions_X, test_uncertanties_X, test_labels_X = Get_predictions_and_uncertainty_with_bagging(x_test_features_path, x_test_labels_path, x_model_folder + f'/20_models/fold_{fold_no}', results_saving_folder, ast.literal_eval(features_to_keep), 'impact site x', model_type)\n",
    "            test_r2_Y, test_ensemble_predictions_Y, test_uncertanties_Y, test_labels_Y = Get_predictions_and_uncertainty_with_bagging(y_test_features_path, y_test_labels_path, y_model_folder + f'/20_models/fold_{fold_no}', results_saving_folder, ast.literal_eval(features_to_keep), 'impact site y', model_type)\n",
    "            \n",
    "        else:\n",
    "            #predicting the test and train sets with the NON bagging models\n",
    "            test_r2_X, test_ensemble_predictions_X, test_uncertanties_X, test_labels_X = Get_predictions_and_uncertainty_single_model(x_test_features_path, x_test_labels_path, x_model_folder + f'/1_models/fold_{fold_no}', results_saving_folder, ast.literal_eval(features_to_keep), 'impact site x', model_type)\n",
    "            test_r2_Y, test_ensemble_predictions_Y, test_uncertanties_Y, test_labels_Y = Get_predictions_and_uncertainty_single_model(y_test_features_path, y_test_labels_path, y_model_folder + f'/1_models/fold_{fold_no}', results_saving_folder, ast.literal_eval(features_to_keep), 'impact site y', model_type)\n",
    "\n",
    "        random_examples = random.sample(range(51), 30)\n",
    "        r2 = parody_plot_with_std(test_labels_X[random_examples], test_ensemble_predictions_X[random_examples], test_uncertanties_X[random_examples], None, 'impact site x', model_type, testtrain='Test', show=True)\n",
    "        r2 = parody_plot_with_std(test_labels_X[random_examples], test_ensemble_predictions_X[random_examples], np.ones(test_uncertanties_X[random_examples].shape) * np.mean(test_uncertanties_X), None, 'impact site x', model_type, testtrain='Test', show=True)\n",
    "        \n",
    "        # for test_example_no in range(len(test_ensemble_predictions_X)): #COMMENT goes through all test examples... if you want a specific one, specify the test_example_no\n",
    "        test_example_no = 1\n",
    "        plot_impact_site_with_uncertainty_2D_with_ellipse_before_recalibration([68, 95, 99.7], test_ensemble_predictions_X[test_example_no], test_uncertanties_X[test_example_no]/2, test_ensemble_predictions_Y[test_example_no], test_uncertanties_Y[test_example_no]/2, test_labels_X[test_example_no], test_labels_Y[test_example_no], saving_path=None)\n",
    "        # plot_impact_site_with_uncertainty_2D_with_ellipse_after_recalibration([68, 95, 99.7], test_ensemble_predictions_X[test_example_no], test_uncertanties_X[test_example_no]/2, test_ensemble_predictions_Y[test_example_no], test_uncertanties_Y[test_example_no]/2, test_labels_X[test_example_no], test_labels_Y[test_example_no], saving_path=None)\n",
    "        # plot_impact_site_with_uncertainty_2D_with_ellipse_using_distribution([68, 95, 99.7], test_ensemble_predictions_X[test_example_no], 0, test_ensemble_predictions_Y[test_example_no], 0, test_labels_X[test_example_no], test_labels_Y[test_example_no], saving_path=None) #COMMENT just plotting the point estimate\n",
    "        \n",
    "        '''recalibrating...'''\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
