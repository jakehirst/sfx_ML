{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook runs the code in bagging_models.py for uncertainty quantification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forestci is an optional dependency. To install latest forestci compatabilty with scikit-learn>=0.24, run pip install git+git://github.com/scikit-learn-contrib/forest-confidence-interval.git\n",
      "XGBoost is an optional dependency. If you want to use XGBoost models, please manually install xgboost package with pip install xgboost. If have error with finding libxgboost.dylib library, dobrew install libomp. If do not have brew on your system, first do ruby -e \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)\" from the Terminal\n",
      "scikit-lego is an optional dependency, enabling use of the LowessRegression model. If you want to use this model, do \"pip install scikit-lego\"\n",
      "['init z', 'init y', 'init x', 'max_prop_speed', 'avg_prop_speed', 'dist btw frts', 'crack len', 'linearity', 'max thickness', 'mean thickness', 'median_thickness', 'var_thickness', 'std_thickness', 'thickness_at_init', 'max_kink', 'abs_val_mean_kink', 'mean_kink', 'sum_kink', 'abs_val_sum_kink', 'median_kink', 'std_kink', 'var_kink', 'avg_ori', 'angle_btw', 'phi', 'theta']\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "'''First, we need to define the path of where to get the dataset, and define other parameters that we will need'''\n",
    "import sys\n",
    "sys.path.append('/Users/jakehirst/Desktop/sfx/sfx_ML_code/sfx_ML/New_Models')\n",
    "\n",
    "from Bagging_models import *\n",
    "from ReCalibration import *\n",
    "from Backward_feature_selection import *\n",
    "import ast\n",
    "\n",
    "model_types = ['ANN', 'RF', 'GPR','ridge']\n",
    "# model_types = ['ridge']\n",
    "all_labels = ['height', 'phi', 'theta', \n",
    "                            'impact site x', 'impact site y', 'impact site z', \n",
    "                            'impact site r', 'impact site phi', 'impact site theta']\n",
    "\n",
    "all_labels = ['height', \n",
    "                            'impact site x', 'impact site y', 'impact site z', \n",
    "                            'impact site r', 'impact site phi', 'impact site theta']\n",
    "\n",
    "num_models_list = [20]\n",
    "labels_to_predict = ['impact site x', 'impact site y', 'height']\n",
    "labels_to_predict = ['height']\n",
    "\n",
    "with_or_without_transformations = 'with'\n",
    "with_or_without_transformations = 'without'\n",
    "\n",
    "Paper2_path = f'/Volumes/Jake_ssd/Paper 2/{with_or_without_transformations}_transformations'\n",
    "Paper2_path = f'/Volumes/Jake_ssd/with_phi_theta'\n",
    "if(not os.path.exists(Paper2_path)): os.makedirs(Paper2_path)\n",
    "model_folder = Paper2_path + f'/UQ_bagging_models_{with_or_without_transformations}_transformations'\n",
    "data_folder = Paper2_path + '/5fold_datasets'\n",
    "results_folder = Paper2_path + '/Compare_Code_5_fold_ensemble_results'\n",
    "# hyperparam_folder = Paper2_path + f'/bayesian_optimization_{with_or_without_transformations}_transformations'\n",
    "hyperparam_folder = f'/Volumes/Jake_ssd/Paper 2/{with_or_without_transformations}_transformations' + f'/bayesian_optimization_{with_or_without_transformations}_transformations'\n",
    "\n",
    "\n",
    "image_folder = '/Users/jakehirst/Desktop/sfx/sfx_ML_data/images_sfx/new_dataset/Visible_cracks'\n",
    "\n",
    "if(with_or_without_transformations == 'with'):\n",
    "    full_dataset_pathname = \"/Volumes/Jake_ssd/Paper 1/Paper_1_results_WITH_feature_engineering/dataset/feature_transformations_2023-11-16/height/HEIGHTALL_TRANSFORMED_FEATURES.csv\"\n",
    "    backward_feat_selection_results_folder = '/Volumes/Jake_ssd/Paper 1/Paper_1_results_WITH_feature_engineering/results'\n",
    "else:\n",
    "    # full_dataset_pathname = \"/Volumes/Jake_ssd/Paper 1/Paper_1_results_no_feature_engineering/dataset/New_Crack_Len_FULL_OG_dataframe_2023_11_16.csv\"\n",
    "    full_dataset_pathname = \"/Volumes/Jake_ssd/Paper 2/New_Crack_Len_FULL_OG_dataframe_2024_02_22.csv\"\n",
    "    backward_feat_selection_results_folder = Paper2_path + '/Paper_2_results_WITHOUT_feature_engineering/results' \n",
    "    df = pd.read_csv(full_dataset_pathname, index_col=0)\n",
    "    all_features = df.columns\n",
    "    all_features = all_features.drop(all_labels)\n",
    "    all_features = str(all_features.drop('timestep_init').to_list())\n",
    "\n",
    "    print(all_features)\n",
    " \n",
    "\n",
    "\n",
    "'''Only have to uncomment this if the 5 fold datasets have not been made or need to be remade'''\n",
    "# make_5_fold_datasets(data_folder, full_dataset_pathname, image_folder)\n",
    "\n",
    "\n",
    "print('ALL_TRANSFORMED_FEATURES' in full_dataset_pathname)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using just the basic features\n",
      "using just the basic features\n",
      "using just the basic features\n",
      "using just the basic features\n",
      "{'height': {'ANN': \"['init z', 'init y', 'init x', 'max_prop_speed', 'avg_prop_speed', 'dist btw frts', 'crack len', 'linearity', 'max thickness', 'mean thickness', 'median_thickness', 'var_thickness', 'std_thickness', 'thickness_at_init', 'max_kink', 'abs_val_mean_kink', 'mean_kink', 'sum_kink', 'abs_val_sum_kink', 'median_kink', 'std_kink', 'var_kink', 'avg_ori', 'angle_btw', 'phi', 'theta']\", 'RF': \"['init z', 'init y', 'init x', 'max_prop_speed', 'avg_prop_speed', 'dist btw frts', 'crack len', 'linearity', 'max thickness', 'mean thickness', 'median_thickness', 'var_thickness', 'std_thickness', 'thickness_at_init', 'max_kink', 'abs_val_mean_kink', 'mean_kink', 'sum_kink', 'abs_val_sum_kink', 'median_kink', 'std_kink', 'var_kink', 'avg_ori', 'angle_btw', 'phi', 'theta']\", 'GPR': \"['init z', 'init y', 'init x', 'max_prop_speed', 'avg_prop_speed', 'dist btw frts', 'crack len', 'linearity', 'max thickness', 'mean thickness', 'median_thickness', 'var_thickness', 'std_thickness', 'thickness_at_init', 'max_kink', 'abs_val_mean_kink', 'mean_kink', 'sum_kink', 'abs_val_sum_kink', 'median_kink', 'std_kink', 'var_kink', 'avg_ori', 'angle_btw', 'phi', 'theta']\", 'ridge': \"['init z', 'init y', 'init x', 'max_prop_speed', 'avg_prop_speed', 'dist btw frts', 'crack len', 'linearity', 'max thickness', 'mean thickness', 'median_thickness', 'var_thickness', 'std_thickness', 'thickness_at_init', 'max_kink', 'abs_val_mean_kink', 'mean_kink', 'sum_kink', 'abs_val_sum_kink', 'median_kink', 'std_kink', 'var_kink', 'avg_ori', 'angle_btw', 'phi', 'theta']\"}}\n"
     ]
    }
   ],
   "source": [
    "'''get the appropriate features that each model will use based on backward feature elimination'''\n",
    "all_features_to_keep = {}\n",
    "\n",
    "min_features = 1 #minimum number of features you want to select from BFS (backward feature selection)\n",
    "max_features = 25 #maximum number of features you want to select from BFS\n",
    "for label in labels_to_predict:\n",
    "    all_features_to_keep[label] = {}\n",
    "    for model_type in model_types:\n",
    "        \n",
    "        if('ALL_TRANSFORMED_FEATURES' in full_dataset_pathname):\n",
    "            print('true')\n",
    "        #TODO use code below if using feature selection\n",
    "            best_features = get_best_features(backward_feat_selection_results_folder, label, model_type, min_features, max_features)\n",
    "            all_features_to_keep[label][model_type] = best_features\n",
    "        \n",
    "        else:\n",
    "            print('using just the basic features')\n",
    "            #TODO use code below if NOT using feature selection\n",
    "            all_features_to_keep[label][model_type] = all_features\n",
    "\n",
    "print(all_features_to_keep)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\\ Predicting height using ANN $$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "\n",
      "/Volumes/Jake_ssd/with_phi_theta/5fold_datasets/height/fold1/train_features.csv\n",
      "['init z', 'init y', 'init x', 'max_prop_speed', 'avg_prop_speed', 'dist btw frts', 'crack len', 'linearity', 'max thickness', 'mean thickness', 'median_thickness', 'var_thickness', 'std_thickness', 'thickness_at_init', 'max_kink', 'abs_val_mean_kink', 'mean_kink', 'sum_kink', 'abs_val_sum_kink', 'median_kink', 'std_kink', 'var_kink', 'avg_ori', 'angle_btw', 'phi', 'theta']\n",
      "working on model 0\n",
      "patience reached\n",
      "End train R2 score = 0.3472033100059535 validation R2 score = 0.09053422734504701\n",
      "working on model 1\n",
      "patience reached\n",
      "End train R2 score = 0.33891903714210225 validation R2 score = 0.34025627566900807\n",
      "working on model 2\n",
      "patience reached\n",
      "End train R2 score = 0.3159167932850806 validation R2 score = 0.12432256152780852\n",
      "working on model 3\n",
      "patience reached\n",
      "End train R2 score = 0.40751584440932065 validation R2 score = 0.3484933692515825\n",
      "working on model 4\n",
      "patience reached\n",
      "End train R2 score = 0.2935790347126672 validation R2 score = 0.328284994710087\n",
      "working on model 5\n",
      "patience reached\n",
      "End train R2 score = 0.11347985744756028 validation R2 score = -0.09057590765886325\n",
      "working on model 6\n",
      "patience reached\n",
      "End train R2 score = 0.27943740352482027 validation R2 score = 0.4440327075486671\n",
      "working on model 7\n",
      "patience reached\n",
      "End train R2 score = 0.1752644298878051 validation R2 score = 0.1689930271154123\n",
      "working on model 8\n",
      "patience reached\n",
      "End train R2 score = 0.3182100467347022 validation R2 score = 0.1948756334486369\n",
      "working on model 9\n",
      "patience reached\n",
      "End train R2 score = 0.18491301286418205 validation R2 score = 0.030057363101135715\n",
      "working on model 10\n",
      "patience reached\n",
      "End train R2 score = 0.3097634975688637 validation R2 score = 0.06802764292453223\n",
      "working on model 11\n",
      "patience reached\n",
      "End train R2 score = 0.3801541431950596 validation R2 score = 0.27991819316355193\n",
      "working on model 12\n",
      "patience reached\n",
      "End train R2 score = 0.2625062555538974 validation R2 score = -0.012634039632281935\n",
      "working on model 13\n",
      "patience reached\n",
      "End train R2 score = 0.35971055277619257 validation R2 score = 0.286478631184089\n",
      "working on model 14\n",
      "patience reached\n",
      "End train R2 score = 0.30995260433606875 validation R2 score = 0.21416798098563294\n",
      "working on model 15\n",
      "patience reached\n",
      "End train R2 score = 0.42898765109193027 validation R2 score = -0.003919609368989718\n",
      "working on model 16\n",
      "patience reached\n",
      "End train R2 score = 0.3256647176685 validation R2 score = 0.11293953975558557\n",
      "working on model 17\n",
      "patience reached\n",
      "End train R2 score = 0.274549471060742 validation R2 score = 0.1191291966333764\n",
      "working on model 18\n",
      "patience reached\n",
      "End train R2 score = 0.3285911323489039 validation R2 score = 0.18339434210558703\n",
      "working on model 19\n",
      "patience reached\n",
      "End train R2 score = 0.3695489299250977 validation R2 score = 0.24328798610294833\n",
      "\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\\ Predicting height using RF $$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "\n",
      "/Volumes/Jake_ssd/with_phi_theta/5fold_datasets/height/fold1/train_features.csv\n",
      "['init z', 'init y', 'init x', 'max_prop_speed', 'avg_prop_speed', 'dist btw frts', 'crack len', 'linearity', 'max thickness', 'mean thickness', 'median_thickness', 'var_thickness', 'std_thickness', 'thickness_at_init', 'max_kink', 'abs_val_mean_kink', 'mean_kink', 'sum_kink', 'abs_val_sum_kink', 'median_kink', 'std_kink', 'var_kink', 'avg_ori', 'angle_btw', 'phi', 'theta']\n",
      "working on model 0\n",
      "working on model 1\n",
      "working on model 2\n",
      "working on model 3\n",
      "working on model 4\n",
      "working on model 5\n",
      "working on model 6\n",
      "working on model 7\n",
      "working on model 8\n",
      "working on model 9\n",
      "working on model 10\n",
      "working on model 11\n",
      "working on model 12\n",
      "working on model 13\n",
      "working on model 14\n",
      "working on model 15\n",
      "working on model 16\n",
      "working on model 17\n",
      "working on model 18\n",
      "working on model 19\n",
      "\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\\ Predicting height using GPR $$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "\n",
      "/Volumes/Jake_ssd/with_phi_theta/5fold_datasets/height/fold1/train_features.csv\n",
      "['init z', 'init y', 'init x', 'max_prop_speed', 'avg_prop_speed', 'dist btw frts', 'crack len', 'linearity', 'max thickness', 'mean thickness', 'median_thickness', 'var_thickness', 'std_thickness', 'thickness_at_init', 'max_kink', 'abs_val_mean_kink', 'mean_kink', 'sum_kink', 'abs_val_sum_kink', 'median_kink', 'std_kink', 'var_kink', 'avg_ori', 'angle_btw', 'phi', 'theta']\n",
      "working on model 0\n",
      "working on model 1\n",
      "working on model 2\n",
      "working on model 3\n",
      "working on model 4\n",
      "working on model 5\n",
      "working on model 6\n",
      "working on model 7\n",
      "working on model 8\n",
      "working on model 9\n",
      "working on model 10\n",
      "working on model 11\n",
      "working on model 12\n",
      "working on model 13\n",
      "working on model 14\n",
      "working on model 15\n",
      "working on model 16\n",
      "working on model 17\n",
      "working on model 18\n",
      "working on model 19\n",
      "\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\\ Predicting height using ridge $$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "\n",
      "/Volumes/Jake_ssd/with_phi_theta/5fold_datasets/height/fold1/train_features.csv\n",
      "['init z', 'init y', 'init x', 'max_prop_speed', 'avg_prop_speed', 'dist btw frts', 'crack len', 'linearity', 'max thickness', 'mean thickness', 'median_thickness', 'var_thickness', 'std_thickness', 'thickness_at_init', 'max_kink', 'abs_val_mean_kink', 'mean_kink', 'sum_kink', 'abs_val_sum_kink', 'median_kink', 'std_kink', 'var_kink', 'avg_ori', 'angle_btw', 'phi', 'theta']\n",
      "working on model 0\n",
      "working on model 1\n",
      "working on model 2\n",
      "working on model 3\n",
      "working on model 4\n",
      "working on model 5\n",
      "working on model 6\n",
      "working on model 7\n",
      "working on model 8\n",
      "working on model 9\n",
      "working on model 10\n",
      "working on model 11\n",
      "working on model 12\n",
      "working on model 13\n",
      "working on model 14\n",
      "working on model 15\n",
      "working on model 16\n",
      "working on model 17\n",
      "working on model 18\n",
      "working on model 19\n",
      "\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\\ Predicting height using ANN $$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "\n",
      "/Volumes/Jake_ssd/with_phi_theta/5fold_datasets/height/fold2/train_features.csv\n",
      "['init z', 'init y', 'init x', 'max_prop_speed', 'avg_prop_speed', 'dist btw frts', 'crack len', 'linearity', 'max thickness', 'mean thickness', 'median_thickness', 'var_thickness', 'std_thickness', 'thickness_at_init', 'max_kink', 'abs_val_mean_kink', 'mean_kink', 'sum_kink', 'abs_val_sum_kink', 'median_kink', 'std_kink', 'var_kink', 'avg_ori', 'angle_btw', 'phi', 'theta']\n",
      "working on model 0\n",
      "patience reached\n",
      "End train R2 score = 0.21050200356602622 validation R2 score = 0.1941919858708101\n",
      "working on model 1\n",
      "patience reached\n",
      "End train R2 score = 0.356498009556652 validation R2 score = 0.3674708987680887\n",
      "working on model 2\n",
      "patience reached\n",
      "End train R2 score = 0.2557151380208047 validation R2 score = 0.16210455813898905\n",
      "working on model 3\n",
      "patience reached\n",
      "End train R2 score = 0.20071318083320766 validation R2 score = 0.00434040898916932\n",
      "working on model 4\n",
      "patience reached\n",
      "End train R2 score = 0.28617907918941177 validation R2 score = -0.19118514299263034\n",
      "working on model 5\n",
      "patience reached\n",
      "End train R2 score = 0.3073518570427576 validation R2 score = 0.21065022589061766\n",
      "working on model 6\n",
      "patience reached\n",
      "End train R2 score = 0.2156276107815558 validation R2 score = -0.08525504779750515\n",
      "working on model 7\n",
      "patience reached\n",
      "End train R2 score = 0.2615947005764576 validation R2 score = 0.2473406706454061\n",
      "working on model 8\n",
      "patience reached\n",
      "End train R2 score = 0.12859408681664586 validation R2 score = 0.1433841964563093\n",
      "working on model 9\n",
      "patience reached\n",
      "End train R2 score = 0.4846571745827767 validation R2 score = 0.4227857993798705\n",
      "working on model 10\n",
      "patience reached\n",
      "End train R2 score = 0.5101355619734727 validation R2 score = 0.16664284834092247\n",
      "working on model 11\n",
      "patience reached\n",
      "End train R2 score = 0.3078195218342671 validation R2 score = 0.3079345201550707\n",
      "working on model 12\n",
      "patience reached\n",
      "End train R2 score = 0.34139522921312637 validation R2 score = 0.2909581048469426\n",
      "working on model 13\n",
      "patience reached\n",
      "End train R2 score = 0.31509512994032773 validation R2 score = 0.13196044924398842\n",
      "working on model 14\n",
      "patience reached\n",
      "End train R2 score = 0.2496428743696778 validation R2 score = 0.1382596488105412\n",
      "working on model 15\n",
      "patience reached\n",
      "End train R2 score = 0.33994583252665944 validation R2 score = 0.17367549782411285\n",
      "working on model 16\n",
      "patience reached\n",
      "End train R2 score = 0.39801827208742313 validation R2 score = 0.01959525848161947\n",
      "working on model 17\n",
      "patience reached\n",
      "End train R2 score = 0.3852989108893069 validation R2 score = 0.07603438055219569\n",
      "working on model 18\n",
      "patience reached\n",
      "End train R2 score = 0.33878199551385524 validation R2 score = 0.2699405082307962\n",
      "working on model 19\n",
      "patience reached\n",
      "End train R2 score = 0.2309950223413353 validation R2 score = -0.10804715845388801\n",
      "\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\\ Predicting height using RF $$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "\n",
      "/Volumes/Jake_ssd/with_phi_theta/5fold_datasets/height/fold2/train_features.csv\n",
      "['init z', 'init y', 'init x', 'max_prop_speed', 'avg_prop_speed', 'dist btw frts', 'crack len', 'linearity', 'max thickness', 'mean thickness', 'median_thickness', 'var_thickness', 'std_thickness', 'thickness_at_init', 'max_kink', 'abs_val_mean_kink', 'mean_kink', 'sum_kink', 'abs_val_sum_kink', 'median_kink', 'std_kink', 'var_kink', 'avg_ori', 'angle_btw', 'phi', 'theta']\n",
      "working on model 0\n",
      "working on model 1\n",
      "working on model 2\n",
      "working on model 3\n",
      "working on model 4\n",
      "working on model 5\n",
      "working on model 6\n",
      "working on model 7\n",
      "working on model 8\n",
      "working on model 9\n",
      "working on model 10\n",
      "working on model 11\n",
      "working on model 12\n",
      "working on model 13\n",
      "working on model 14\n",
      "working on model 15\n",
      "working on model 16\n",
      "working on model 17\n",
      "working on model 18\n",
      "working on model 19\n",
      "\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\\ Predicting height using GPR $$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "\n",
      "/Volumes/Jake_ssd/with_phi_theta/5fold_datasets/height/fold2/train_features.csv\n",
      "['init z', 'init y', 'init x', 'max_prop_speed', 'avg_prop_speed', 'dist btw frts', 'crack len', 'linearity', 'max thickness', 'mean thickness', 'median_thickness', 'var_thickness', 'std_thickness', 'thickness_at_init', 'max_kink', 'abs_val_mean_kink', 'mean_kink', 'sum_kink', 'abs_val_sum_kink', 'median_kink', 'std_kink', 'var_kink', 'avg_ori', 'angle_btw', 'phi', 'theta']\n",
      "working on model 0\n",
      "working on model 1\n",
      "working on model 2\n",
      "working on model 3\n",
      "working on model 4\n",
      "working on model 5\n",
      "working on model 6\n",
      "working on model 7\n",
      "working on model 8\n",
      "working on model 9\n",
      "working on model 10\n",
      "working on model 11\n",
      "working on model 12\n",
      "working on model 13\n",
      "working on model 14\n",
      "working on model 15\n",
      "working on model 16\n",
      "working on model 17\n",
      "working on model 18\n",
      "working on model 19\n",
      "\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\\ Predicting height using ridge $$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "\n",
      "/Volumes/Jake_ssd/with_phi_theta/5fold_datasets/height/fold2/train_features.csv\n",
      "['init z', 'init y', 'init x', 'max_prop_speed', 'avg_prop_speed', 'dist btw frts', 'crack len', 'linearity', 'max thickness', 'mean thickness', 'median_thickness', 'var_thickness', 'std_thickness', 'thickness_at_init', 'max_kink', 'abs_val_mean_kink', 'mean_kink', 'sum_kink', 'abs_val_sum_kink', 'median_kink', 'std_kink', 'var_kink', 'avg_ori', 'angle_btw', 'phi', 'theta']\n",
      "working on model 0\n",
      "working on model 1\n",
      "working on model 2\n",
      "working on model 3\n",
      "working on model 4\n",
      "working on model 5\n",
      "working on model 6\n",
      "working on model 7\n",
      "working on model 8\n",
      "working on model 9\n",
      "working on model 10\n",
      "working on model 11\n",
      "working on model 12\n",
      "working on model 13\n",
      "working on model 14\n",
      "working on model 15\n",
      "working on model 16\n",
      "working on model 17\n",
      "working on model 18\n",
      "working on model 19\n",
      "\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\\ Predicting height using ANN $$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "\n",
      "/Volumes/Jake_ssd/with_phi_theta/5fold_datasets/height/fold3/train_features.csv\n",
      "['init z', 'init y', 'init x', 'max_prop_speed', 'avg_prop_speed', 'dist btw frts', 'crack len', 'linearity', 'max thickness', 'mean thickness', 'median_thickness', 'var_thickness', 'std_thickness', 'thickness_at_init', 'max_kink', 'abs_val_mean_kink', 'mean_kink', 'sum_kink', 'abs_val_sum_kink', 'median_kink', 'std_kink', 'var_kink', 'avg_ori', 'angle_btw', 'phi', 'theta']\n",
      "working on model 0\n",
      "patience reached\n",
      "End train R2 score = 0.3039927935765335 validation R2 score = 0.022061364036765507\n",
      "working on model 1\n",
      "patience reached\n",
      "End train R2 score = 0.37917010204823154 validation R2 score = 0.04535899955257583\n",
      "working on model 2\n",
      "patience reached\n",
      "End train R2 score = 0.2627613495600376 validation R2 score = 0.3124357628259178\n",
      "working on model 3\n",
      "patience reached\n",
      "End train R2 score = 0.2587713291966588 validation R2 score = 0.054603346963897015\n",
      "working on model 4\n",
      "patience reached\n",
      "End train R2 score = 0.3113316911509135 validation R2 score = 0.28834269012419356\n",
      "working on model 5\n",
      "patience reached\n",
      "End train R2 score = 0.43380075169730037 validation R2 score = 0.23288519627267845\n",
      "working on model 6\n",
      "patience reached\n",
      "End train R2 score = 0.2764259938261112 validation R2 score = 0.04728103279257678\n",
      "working on model 7\n",
      "patience reached\n",
      "End train R2 score = 0.41538967501390256 validation R2 score = 0.20188477237883884\n",
      "working on model 8\n",
      "patience reached\n",
      "End train R2 score = 0.3439132834108116 validation R2 score = 0.29062664667156746\n",
      "working on model 9\n",
      "patience reached\n",
      "End train R2 score = 0.28335928745759564 validation R2 score = 0.19510649765599541\n",
      "working on model 10\n",
      "patience reached\n",
      "End train R2 score = 0.26651297633112025 validation R2 score = -0.05299989157432461\n",
      "working on model 11\n",
      "patience reached\n",
      "End train R2 score = 0.30632536128595333 validation R2 score = -0.10156789332058591\n",
      "working on model 12\n",
      "patience reached\n",
      "End train R2 score = 0.3677560838103361 validation R2 score = 0.21930843216023788\n",
      "working on model 13\n",
      "patience reached\n",
      "End train R2 score = 0.20481813195309462 validation R2 score = -0.001641594795640744\n",
      "working on model 14\n",
      "patience reached\n",
      "End train R2 score = 0.48596444883279666 validation R2 score = 0.18379968031158533\n",
      "working on model 15\n",
      "patience reached\n",
      "End train R2 score = 0.3310827623653031 validation R2 score = 0.22040494147461953\n",
      "working on model 16\n",
      "patience reached\n",
      "End train R2 score = 0.23219389561937243 validation R2 score = -0.1768869455815063\n",
      "working on model 17\n",
      "patience reached\n",
      "End train R2 score = 0.10293969333684183 validation R2 score = -0.20869142624064585\n",
      "working on model 18\n",
      "patience reached\n",
      "End train R2 score = 0.32811534031154754 validation R2 score = 0.16675556093606203\n",
      "working on model 19\n",
      "patience reached\n",
      "End train R2 score = 0.39831879886089094 validation R2 score = 0.10408458298159562\n",
      "\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\\ Predicting height using RF $$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "\n",
      "/Volumes/Jake_ssd/with_phi_theta/5fold_datasets/height/fold3/train_features.csv\n",
      "['init z', 'init y', 'init x', 'max_prop_speed', 'avg_prop_speed', 'dist btw frts', 'crack len', 'linearity', 'max thickness', 'mean thickness', 'median_thickness', 'var_thickness', 'std_thickness', 'thickness_at_init', 'max_kink', 'abs_val_mean_kink', 'mean_kink', 'sum_kink', 'abs_val_sum_kink', 'median_kink', 'std_kink', 'var_kink', 'avg_ori', 'angle_btw', 'phi', 'theta']\n",
      "working on model 0\n",
      "working on model 1\n",
      "working on model 2\n",
      "working on model 3\n",
      "working on model 4\n",
      "working on model 5\n",
      "working on model 6\n",
      "working on model 7\n",
      "working on model 8\n",
      "working on model 9\n",
      "working on model 10\n",
      "working on model 11\n",
      "working on model 12\n",
      "working on model 13\n",
      "working on model 14\n",
      "working on model 15\n",
      "working on model 16\n",
      "working on model 17\n",
      "working on model 18\n",
      "working on model 19\n",
      "\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\\ Predicting height using GPR $$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "\n",
      "/Volumes/Jake_ssd/with_phi_theta/5fold_datasets/height/fold3/train_features.csv\n",
      "['init z', 'init y', 'init x', 'max_prop_speed', 'avg_prop_speed', 'dist btw frts', 'crack len', 'linearity', 'max thickness', 'mean thickness', 'median_thickness', 'var_thickness', 'std_thickness', 'thickness_at_init', 'max_kink', 'abs_val_mean_kink', 'mean_kink', 'sum_kink', 'abs_val_sum_kink', 'median_kink', 'std_kink', 'var_kink', 'avg_ori', 'angle_btw', 'phi', 'theta']\n",
      "working on model 0\n",
      "working on model 1\n",
      "working on model 2\n",
      "working on model 3\n",
      "working on model 4\n",
      "working on model 5\n",
      "working on model 6\n",
      "working on model 7\n",
      "working on model 8\n",
      "working on model 9\n",
      "working on model 10\n",
      "working on model 11\n",
      "working on model 12\n",
      "working on model 13\n",
      "working on model 14\n",
      "working on model 15\n",
      "working on model 16\n",
      "working on model 17\n",
      "working on model 18\n",
      "working on model 19\n",
      "\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\\ Predicting height using ridge $$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "\n",
      "/Volumes/Jake_ssd/with_phi_theta/5fold_datasets/height/fold3/train_features.csv\n",
      "['init z', 'init y', 'init x', 'max_prop_speed', 'avg_prop_speed', 'dist btw frts', 'crack len', 'linearity', 'max thickness', 'mean thickness', 'median_thickness', 'var_thickness', 'std_thickness', 'thickness_at_init', 'max_kink', 'abs_val_mean_kink', 'mean_kink', 'sum_kink', 'abs_val_sum_kink', 'median_kink', 'std_kink', 'var_kink', 'avg_ori', 'angle_btw', 'phi', 'theta']\n",
      "working on model 0\n",
      "working on model 1\n",
      "working on model 2\n",
      "working on model 3\n",
      "working on model 4\n",
      "working on model 5\n",
      "working on model 6\n",
      "working on model 7\n",
      "working on model 8\n",
      "working on model 9\n",
      "working on model 10\n",
      "working on model 11\n",
      "working on model 12\n",
      "working on model 13\n",
      "working on model 14\n",
      "working on model 15\n",
      "working on model 16\n",
      "working on model 17\n",
      "working on model 18\n",
      "working on model 19\n",
      "\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\\ Predicting height using ANN $$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "\n",
      "/Volumes/Jake_ssd/with_phi_theta/5fold_datasets/height/fold4/train_features.csv\n",
      "['init z', 'init y', 'init x', 'max_prop_speed', 'avg_prop_speed', 'dist btw frts', 'crack len', 'linearity', 'max thickness', 'mean thickness', 'median_thickness', 'var_thickness', 'std_thickness', 'thickness_at_init', 'max_kink', 'abs_val_mean_kink', 'mean_kink', 'sum_kink', 'abs_val_sum_kink', 'median_kink', 'std_kink', 'var_kink', 'avg_ori', 'angle_btw', 'phi', 'theta']\n",
      "working on model 0\n",
      "patience reached\n",
      "End train R2 score = 0.2809113483827428 validation R2 score = 0.25503944858054817\n",
      "working on model 1\n",
      "patience reached\n",
      "End train R2 score = 0.1586725539436965 validation R2 score = -0.014885714305377107\n",
      "working on model 2\n",
      "patience reached\n",
      "End train R2 score = 0.26419559268342574 validation R2 score = 0.042052573987655606\n",
      "working on model 3\n",
      "patience reached\n",
      "End train R2 score = 0.3108724688490949 validation R2 score = 0.3013371480411394\n",
      "working on model 4\n",
      "patience reached\n",
      "End train R2 score = 0.338763477349466 validation R2 score = 0.20634228721734205\n",
      "working on model 5\n",
      "patience reached\n",
      "End train R2 score = 0.4121215226005901 validation R2 score = 0.1998878284672756\n",
      "working on model 6\n",
      "patience reached\n",
      "End train R2 score = 0.19065821598349098 validation R2 score = 0.14830276323525438\n",
      "working on model 7\n",
      "patience reached\n",
      "End train R2 score = 0.35335614484201217 validation R2 score = 0.3184941077075858\n",
      "working on model 8\n",
      "patience reached\n",
      "End train R2 score = 0.21883209864841957 validation R2 score = -0.01482096700978075\n",
      "working on model 9\n",
      "patience reached\n",
      "End train R2 score = 0.26642398953704516 validation R2 score = 0.07477078185445452\n",
      "working on model 10\n",
      "patience reached\n",
      "End train R2 score = 0.34792117863470395 validation R2 score = 0.1372567950084599\n",
      "working on model 11\n",
      "patience reached\n",
      "End train R2 score = 0.3262541336944358 validation R2 score = 0.20984871403964955\n",
      "working on model 12\n",
      "patience reached\n",
      "End train R2 score = 0.3780432085478109 validation R2 score = 0.022337211938635804\n",
      "working on model 13\n",
      "patience reached\n",
      "End train R2 score = 0.37050149991818415 validation R2 score = 0.4795990849797208\n",
      "working on model 14\n",
      "patience reached\n",
      "End train R2 score = 0.38903806367178473 validation R2 score = 0.09232413392206096\n",
      "working on model 15\n",
      "patience reached\n",
      "End train R2 score = 0.3210533318491692 validation R2 score = 0.12640974811052774\n",
      "working on model 16\n",
      "patience reached\n",
      "End train R2 score = 0.3506809270835919 validation R2 score = 0.16620735010539278\n",
      "working on model 17\n",
      "patience reached\n",
      "End train R2 score = 0.40114222500183694 validation R2 score = 0.28002174717723005\n",
      "working on model 18\n",
      "patience reached\n",
      "End train R2 score = 0.3175782755397203 validation R2 score = 0.32097022161983657\n",
      "working on model 19\n",
      "patience reached\n",
      "End train R2 score = 0.21624021080727973 validation R2 score = 0.09214671309871902\n",
      "\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\\ Predicting height using RF $$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "\n",
      "/Volumes/Jake_ssd/with_phi_theta/5fold_datasets/height/fold4/train_features.csv\n",
      "['init z', 'init y', 'init x', 'max_prop_speed', 'avg_prop_speed', 'dist btw frts', 'crack len', 'linearity', 'max thickness', 'mean thickness', 'median_thickness', 'var_thickness', 'std_thickness', 'thickness_at_init', 'max_kink', 'abs_val_mean_kink', 'mean_kink', 'sum_kink', 'abs_val_sum_kink', 'median_kink', 'std_kink', 'var_kink', 'avg_ori', 'angle_btw', 'phi', 'theta']\n",
      "working on model 0\n",
      "working on model 1\n",
      "working on model 2\n",
      "working on model 3\n",
      "working on model 4\n",
      "working on model 5\n",
      "working on model 6\n",
      "working on model 7\n",
      "working on model 8\n",
      "working on model 9\n",
      "working on model 10\n",
      "working on model 11\n",
      "working on model 12\n",
      "working on model 13\n",
      "working on model 14\n",
      "working on model 15\n",
      "working on model 16\n",
      "working on model 17\n",
      "working on model 18\n",
      "working on model 19\n",
      "\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\\ Predicting height using GPR $$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "\n",
      "/Volumes/Jake_ssd/with_phi_theta/5fold_datasets/height/fold4/train_features.csv\n",
      "['init z', 'init y', 'init x', 'max_prop_speed', 'avg_prop_speed', 'dist btw frts', 'crack len', 'linearity', 'max thickness', 'mean thickness', 'median_thickness', 'var_thickness', 'std_thickness', 'thickness_at_init', 'max_kink', 'abs_val_mean_kink', 'mean_kink', 'sum_kink', 'abs_val_sum_kink', 'median_kink', 'std_kink', 'var_kink', 'avg_ori', 'angle_btw', 'phi', 'theta']\n",
      "working on model 0\n",
      "working on model 1\n",
      "working on model 2\n",
      "working on model 3\n",
      "working on model 4\n",
      "working on model 5\n",
      "working on model 6\n",
      "working on model 7\n",
      "working on model 8\n",
      "working on model 9\n",
      "working on model 10\n",
      "working on model 11\n",
      "working on model 12\n",
      "working on model 13\n",
      "working on model 14\n",
      "working on model 15\n",
      "working on model 16\n",
      "working on model 17\n",
      "working on model 18\n",
      "working on model 19\n",
      "\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\\ Predicting height using ridge $$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "\n",
      "/Volumes/Jake_ssd/with_phi_theta/5fold_datasets/height/fold4/train_features.csv\n",
      "['init z', 'init y', 'init x', 'max_prop_speed', 'avg_prop_speed', 'dist btw frts', 'crack len', 'linearity', 'max thickness', 'mean thickness', 'median_thickness', 'var_thickness', 'std_thickness', 'thickness_at_init', 'max_kink', 'abs_val_mean_kink', 'mean_kink', 'sum_kink', 'abs_val_sum_kink', 'median_kink', 'std_kink', 'var_kink', 'avg_ori', 'angle_btw', 'phi', 'theta']\n",
      "working on model 0\n",
      "working on model 1\n",
      "working on model 2\n",
      "working on model 3\n",
      "working on model 4\n",
      "working on model 5\n",
      "working on model 6\n",
      "working on model 7\n",
      "working on model 8\n",
      "working on model 9\n",
      "working on model 10\n",
      "working on model 11\n",
      "working on model 12\n",
      "working on model 13\n",
      "working on model 14\n",
      "working on model 15\n",
      "working on model 16\n",
      "working on model 17\n",
      "working on model 18\n",
      "working on model 19\n",
      "\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\\ Predicting height using ANN $$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "\n",
      "/Volumes/Jake_ssd/with_phi_theta/5fold_datasets/height/fold5/train_features.csv\n",
      "['init z', 'init y', 'init x', 'max_prop_speed', 'avg_prop_speed', 'dist btw frts', 'crack len', 'linearity', 'max thickness', 'mean thickness', 'median_thickness', 'var_thickness', 'std_thickness', 'thickness_at_init', 'max_kink', 'abs_val_mean_kink', 'mean_kink', 'sum_kink', 'abs_val_sum_kink', 'median_kink', 'std_kink', 'var_kink', 'avg_ori', 'angle_btw', 'phi', 'theta']\n",
      "working on model 0\n",
      "patience reached\n",
      "End train R2 score = 0.31145097648743847 validation R2 score = 0.2969963838407289\n",
      "working on model 1\n",
      "patience reached\n",
      "End train R2 score = 0.2192530230188472 validation R2 score = 0.18099325958268753\n",
      "working on model 2\n",
      "patience reached\n",
      "End train R2 score = 0.30445115493418495 validation R2 score = 0.15353551644673147\n",
      "working on model 3\n",
      "patience reached\n",
      "End train R2 score = 0.3000943400866358 validation R2 score = 0.3350895869314843\n",
      "working on model 4\n",
      "patience reached\n",
      "End train R2 score = 0.035552770410208545 validation R2 score = -0.05550218001088503\n",
      "working on model 5\n",
      "patience reached\n",
      "End train R2 score = 0.3158655654864453 validation R2 score = 0.4053520205498744\n",
      "working on model 6\n",
      "patience reached\n",
      "End train R2 score = 0.37716827275532505 validation R2 score = 0.004860535845631397\n",
      "working on model 7\n",
      "patience reached\n",
      "End train R2 score = 0.24412231628660375 validation R2 score = 0.061510735715440856\n",
      "working on model 8\n",
      "patience reached\n",
      "End train R2 score = 0.3297374113761067 validation R2 score = 0.2734027360785769\n",
      "working on model 9\n",
      "patience reached\n",
      "End train R2 score = 0.45667580685758036 validation R2 score = 0.1806244587085437\n",
      "working on model 10\n",
      "patience reached\n",
      "End train R2 score = 0.3659968254062481 validation R2 score = 0.09450611713951962\n",
      "working on model 11\n",
      "patience reached\n",
      "End train R2 score = 0.24287032335754355 validation R2 score = 0.15634182134437957\n",
      "working on model 12\n",
      "patience reached\n",
      "End train R2 score = 0.34287031786135247 validation R2 score = 0.27842774409285853\n",
      "working on model 13\n",
      "patience reached\n",
      "End train R2 score = 0.390660040295276 validation R2 score = 0.2500929039349432\n",
      "working on model 14\n",
      "patience reached\n",
      "End train R2 score = 0.16405255115498152 validation R2 score = 0.13733830379543932\n",
      "working on model 15\n",
      "patience reached\n",
      "End train R2 score = 0.29830217639167844 validation R2 score = 0.2382905362338924\n",
      "working on model 16\n",
      "patience reached\n",
      "End train R2 score = 0.3035703731091819 validation R2 score = 0.02795763986547095\n",
      "working on model 17\n",
      "patience reached\n",
      "End train R2 score = 0.23484377783184862 validation R2 score = 0.14666711405545263\n",
      "working on model 18\n",
      "patience reached\n",
      "End train R2 score = 0.28541506525524996 validation R2 score = 0.1935900011821674\n",
      "working on model 19\n",
      "patience reached\n",
      "End train R2 score = 0.295863831864445 validation R2 score = 0.11039736853864135\n",
      "\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\\ Predicting height using RF $$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "\n",
      "/Volumes/Jake_ssd/with_phi_theta/5fold_datasets/height/fold5/train_features.csv\n",
      "['init z', 'init y', 'init x', 'max_prop_speed', 'avg_prop_speed', 'dist btw frts', 'crack len', 'linearity', 'max thickness', 'mean thickness', 'median_thickness', 'var_thickness', 'std_thickness', 'thickness_at_init', 'max_kink', 'abs_val_mean_kink', 'mean_kink', 'sum_kink', 'abs_val_sum_kink', 'median_kink', 'std_kink', 'var_kink', 'avg_ori', 'angle_btw', 'phi', 'theta']\n",
      "working on model 0\n",
      "working on model 1\n",
      "working on model 2\n",
      "working on model 3\n",
      "working on model 4\n",
      "working on model 5\n",
      "working on model 6\n",
      "working on model 7\n",
      "working on model 8\n",
      "working on model 9\n",
      "working on model 10\n",
      "working on model 11\n",
      "working on model 12\n",
      "working on model 13\n",
      "working on model 14\n",
      "working on model 15\n",
      "working on model 16\n",
      "working on model 17\n",
      "working on model 18\n",
      "working on model 19\n",
      "\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\\ Predicting height using GPR $$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "\n",
      "/Volumes/Jake_ssd/with_phi_theta/5fold_datasets/height/fold5/train_features.csv\n",
      "['init z', 'init y', 'init x', 'max_prop_speed', 'avg_prop_speed', 'dist btw frts', 'crack len', 'linearity', 'max thickness', 'mean thickness', 'median_thickness', 'var_thickness', 'std_thickness', 'thickness_at_init', 'max_kink', 'abs_val_mean_kink', 'mean_kink', 'sum_kink', 'abs_val_sum_kink', 'median_kink', 'std_kink', 'var_kink', 'avg_ori', 'angle_btw', 'phi', 'theta']\n",
      "working on model 0\n",
      "working on model 1\n",
      "working on model 2\n",
      "working on model 3\n",
      "working on model 4\n",
      "working on model 5\n",
      "working on model 6\n",
      "working on model 7\n",
      "working on model 8\n",
      "working on model 9\n",
      "working on model 10\n",
      "working on model 11\n",
      "working on model 12\n",
      "working on model 13\n",
      "working on model 14\n",
      "working on model 15\n",
      "working on model 16\n",
      "working on model 17\n",
      "working on model 18\n",
      "working on model 19\n",
      "\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\\ Predicting height using ridge $$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "\n",
      "/Volumes/Jake_ssd/with_phi_theta/5fold_datasets/height/fold5/train_features.csv\n",
      "['init z', 'init y', 'init x', 'max_prop_speed', 'avg_prop_speed', 'dist btw frts', 'crack len', 'linearity', 'max thickness', 'mean thickness', 'median_thickness', 'var_thickness', 'std_thickness', 'thickness_at_init', 'max_kink', 'abs_val_mean_kink', 'mean_kink', 'sum_kink', 'abs_val_sum_kink', 'median_kink', 'std_kink', 'var_kink', 'avg_ori', 'angle_btw', 'phi', 'theta']\n",
      "working on model 0\n",
      "working on model 1\n",
      "working on model 2\n",
      "working on model 3\n",
      "working on model 4\n",
      "working on model 5\n",
      "working on model 6\n",
      "working on model 7\n",
      "working on model 8\n",
      "working on model 9\n",
      "working on model 10\n",
      "working on model 11\n",
      "working on model 12\n",
      "working on model 13\n",
      "working on model 14\n",
      "working on model 15\n",
      "working on model 16\n",
      "working on model 17\n",
      "working on model 18\n",
      "working on model 19\n"
     ]
    }
   ],
   "source": [
    "'''Now we will make all of the bagging models'''\n",
    "for fold_no in range(1,6):\n",
    "    for model_type in model_types:\n",
    "        for label_to_predict in labels_to_predict:\n",
    "            for num_models in num_models_list:\n",
    "                \n",
    "                print(f'\\n$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\\ Predicting {label_to_predict} using {model_type} $$$$$$$$$$$$$$$$$$$$$$$$$$$$$\\n')\n",
    "                \n",
    "                all_labels = ['height', 'phi', 'theta', \n",
    "                            'impact site x', 'impact site y', 'impact site z', \n",
    "                            'impact site r', 'impact site phi', 'impact site theta']\n",
    "                \n",
    "                all_labels = ['height',\n",
    "                            'impact site x', 'impact site y', 'impact site z', \n",
    "                            'impact site r', 'impact site phi', 'impact site theta']\n",
    "\n",
    "                print(f'{data_folder}/{label_to_predict}/fold{fold_no}/train_features.csv')\n",
    "                training_features = pd.read_csv(f'{data_folder}/{label_to_predict}/fold{fold_no}/train_features.csv').reset_index(drop=True)\n",
    "                training_labels = pd.read_csv(f'{data_folder}/{label_to_predict}/fold{fold_no}/train_labels.csv').reset_index(drop=True)\n",
    "\n",
    "                model_saving_folder = f'{model_folder}/{label_to_predict}/{model_type}/{num_models}_models/fold_{fold_no}'\n",
    "                if(not os.path.exists(model_saving_folder)):\n",
    "                    os.makedirs(model_saving_folder)\n",
    "                    \n",
    "                results_saving_folder = f'{results_folder}/{label_to_predict}/{model_type}/{num_models}_models/fold_{fold_no}'\n",
    "                if(not os.path.exists(results_saving_folder)):\n",
    "                    os.makedirs(results_saving_folder)\n",
    "                # make_dirs(model_saving_folder)\n",
    "                # make_dirs(results_saving_folder)\n",
    "\n",
    "                '''TODO gotta find out what features to use for each label before testing on new dataset'''\n",
    "                features_to_keep = ast.literal_eval(all_features_to_keep[label_to_predict][model_type])\n",
    "                print(features_to_keep)\n",
    "                make_linear_regression_models_for_ensemble(training_features, training_labels, model_saving_folder, label_to_predict, num_models, features_to_keep, hyperparam_folder, model_type=model_type)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL TYPE = ANN\n",
      "LABEL = height\n",
      "fold 1\n",
      "Calibration error = 3.87\n",
      "fold 2\n",
      "Calibration error = 2.89\n",
      "fold 3\n",
      "Calibration error = 1.65\n",
      "fold 4\n",
      "Calibration error = 3.83\n",
      "fold 5\n",
      "Calibration error = 3.47\n",
      "MODEL TYPE = RF\n",
      "LABEL = height\n",
      "fold 1\n",
      "Calibration error = 4.92\n",
      "fold 2\n",
      "Calibration error = 5.04\n",
      "fold 3\n",
      "Calibration error = 4.42\n",
      "fold 4\n",
      "Calibration error = 5.12\n",
      "fold 5\n",
      "Calibration error = 5.32\n",
      "MODEL TYPE = GPR\n",
      "LABEL = height\n",
      "fold 1\n",
      "Calibration error = 9.83\n",
      "fold 2\n",
      "Calibration error = 4.82\n",
      "fold 3\n",
      "Calibration error = 5.49\n",
      "fold 4\n",
      "Calibration error = 6.87\n",
      "fold 5\n",
      "Calibration error = 6.84\n",
      "MODEL TYPE = ridge\n",
      "LABEL = height\n",
      "fold 1\n",
      "Calibration error = 5.66\n",
      "fold 2\n",
      "Calibration error = 4.20\n",
      "fold 3\n",
      "Calibration error = 2.65\n",
      "fold 4\n",
      "Calibration error = 5.70\n",
      "fold 5\n",
      "Calibration error = 5.36\n"
     ]
    }
   ],
   "source": [
    "'''Now we will evaluate the performance of the bagging models'''\n",
    "\n",
    "\n",
    "for model_type in model_types:\n",
    "    print(f'MODEL TYPE = {model_type}')\n",
    "    for label_to_predict in labels_to_predict:\n",
    "        print(f'LABEL = {label_to_predict}')\n",
    "        for num_models in num_models_list:\n",
    "            performance_data = []\n",
    "            for fold_no in range(1,6):\n",
    "                print(f'fold {fold_no}')\n",
    "\n",
    "                #defining folders to get the models and to store the results\n",
    "                model_saving_folder = f'{model_folder}/{label_to_predict}/{model_type}/{num_models}_models/fold_{fold_no}'\n",
    "                results_saving_folder = f'{results_folder}/{label_to_predict}/{model_type}/{num_models}_models/fold_{fold_no}'\n",
    "                \n",
    "                #defining folders where the datasets are coming from (5-fold cv)\n",
    "                test_features_path = Paper2_path + f'/5fold_datasets/{label_to_predict}/fold{fold_no}/test_features.csv'\n",
    "                test_labels_path = Paper2_path + f'/5fold_datasets/{label_to_predict}/fold{fold_no}/test_labels.csv'\n",
    "                train_features_path = Paper2_path + f'/5fold_datasets/{label_to_predict}/fold{fold_no}/train_features.csv'\n",
    "                train_labels_path = Paper2_path + f'/5fold_datasets/{label_to_predict}/fold{fold_no}/train_labels.csv'\n",
    "\n",
    "                #defining the features that each model used (since they vary with each model)\n",
    "                features_to_keep = ast.literal_eval(all_features_to_keep[label_to_predict][model_type])\n",
    "                \n",
    "                #predicting the test and train sets with the bagging models\n",
    "                test_r2, test_ensemble_predictions, test_ensemble_uncertanties, test_labels = Get_predictions_and_uncertainty_with_bagging(test_features_path, test_labels_path, model_saving_folder, results_saving_folder, features_to_keep, label_to_predict, model_type)\n",
    "                train_r2, train_ensemble_predictions, train_ensemble_uncertanties, train_labels = Get_predictions_and_uncertainty_with_bagging(train_features_path, train_labels_path, model_saving_folder, results_saving_folder, features_to_keep, label_to_predict, model_type)\n",
    "\n",
    "                #defining the residual errors of the predictions\n",
    "                train_labels_arr = train_labels\n",
    "                train_predictions_arr = np.array(train_ensemble_predictions)\n",
    "                test_labels_arr = test_labels\n",
    "                test_predictions_arr = np.array(test_ensemble_predictions)\n",
    "                train_residuals = pd.Series(np.abs(train_labels_arr - train_predictions_arr))\n",
    "                test_residuals = pd.Series(np.abs(test_labels_arr - test_predictions_arr))\n",
    "\n",
    "                a = 0\n",
    "                b = 0\n",
    "                '''getting calibration factors *** linear'''\n",
    "                # cf = CorrectionFactors(train_residuals, pd.Series(train_ensemble_uncertanties))\n",
    "                # a, b = cf.nll()\n",
    "                # print(f'a = {a} b = {b}')\n",
    "                # calibrated_train_uncertainties = pd.Series(a * np.array(train_ensemble_uncertanties) + b, name='train_model_errors')\n",
    "                # calibrated_test_uncertainties = pd.Series(a * np.array(test_ensemble_uncertanties) + b, name='test_model_errors')\n",
    "                '''getting calibration factors *** Nonlinear'''\n",
    "                # a, b = get_calibration_factors(train_residuals, train_ensemble_uncertanties)\n",
    "                # print(f'a = {a} b = {b}')\n",
    "                # calibrated_train_uncertainties = pd.Series(a * (train_ensemble_uncertanties**((b/2) + 1)), name='train_model_errors')\n",
    "                # calibrated_test_uncertainties = pd.Series(a * (test_ensemble_uncertanties**((b/2) + 1)), name='test_model_errors')\n",
    "\n",
    "\n",
    "                '''\n",
    "                Calculating and plotting performance metrics as outlined in section 2.3 of Tran et al. (https://dx.doi.org/10.1088/2632-2153/ab7e1a)\n",
    "                \n",
    "                Models should be compared in terms of \n",
    "                1st - accuracy (R^2) \n",
    "                2nd - calibration (miscalibration area)\n",
    "                3rd - sharpness\n",
    "                4th - dispersion\n",
    "                '''\n",
    "                #CALIBRATION plots and miscalibration area\n",
    "                #This tells us how 'honest' our uncertainty values are. A perfect calibration plot would mean for a given confidence interval in our prediction\n",
    "                #(say 90%), we can expect with 90% certainty that the true value falls within that confidence interval.\n",
    "                miscalibration_area, calibration_error = make_calibration_plots(model_type, test_predictions_arr, test_labels_arr, test_ensemble_uncertanties, results_saving_folder)\n",
    "                \n",
    "                #SHARPNESS plots and value\n",
    "                #Models can be calibrated, but all have very dull uncertainty values (they all have large uncertainties). To ensure UQ is meaningful, models\n",
    "                #should a be sharp (i.e. uncertainties should be as small as possible.)\n",
    "                #Sharpness is essentially calculated as the average of predicted standard deviations. #COMMENT Low sharpness values are better.\n",
    "                stdevs = np.array(test_ensemble_uncertanties)/2 #right now, i multiply the stds by 2 to make it look better in parity plots... but this needs the raw std.\n",
    "                sharpness, dispersion = plot_sharpness_curve(stdevs, results_saving_folder)\n",
    "                #DISPERSION value\n",
    "                #Models can be calibrated and sharp, but even so, if they are all similar uncertainties, then this does not tell us much. To ensure more \n",
    "                #meaningful UQ, having a large dispersion of uncertainties is valuable. \n",
    "                #Dispersion is calculated using equation 4 of the paper, which is called the coefficient of variation (Cv). #COMMENT High dispersion (Cv) values are better.\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                # blank_model_for_plot = SklearnModel('RandomForestRegressor')\n",
    "                # mastml_RVE = Error()\n",
    "\n",
    "                # mastml_RVE.plot_real_vs_predicted_error_uncal_cal_overlay(savepath=results_saving_folder, \n",
    "                #                                                         model=blank_model_for_plot, \n",
    "                #                                                         data_type='train', \n",
    "                #                                                         model_errors=pd.Series(train_ensemble_uncertanties) ,\n",
    "                #                                                         model_errors_cal= calibrated_train_uncertainties,\n",
    "                #                                                         residuals= train_residuals, \n",
    "                #                                                         dataset_stdev=np.std(train_labels.to_numpy()), \n",
    "                #                                                         show_figure=False,\n",
    "                #                                                         well_sampled_number=0.025)\n",
    "                \n",
    "                \n",
    "                # mastml_RVE.plot_real_vs_predicted_error_uncal_cal_overlay(savepath=results_saving_folder, \n",
    "                #                                                         model=blank_model_for_plot, \n",
    "                #                                                         data_type='test', \n",
    "                #                                                         model_errors=pd.Series(test_ensemble_uncertanties) ,\n",
    "                #                                                         model_errors_cal= calibrated_test_uncertainties,\n",
    "                #                                                         residuals= test_residuals, \n",
    "                #                                                         dataset_stdev=np.std(train_labels.to_numpy()), \n",
    "                #                                                         show_figure=False,\n",
    "                #                                                         well_sampled_number=0.025)\n",
    "                \n",
    "                '''using library from Palmer et al. to make an rve plot'''\n",
    "                # train_intercept, train_slope, CAL_train_intercept, CAL_train_slope, train_intercept, test_slope, CAL_test_intercept, CAL_test_slope = make_RVE_plots(label_to_predict, model_type, test_ensemble_predictions, test_ensemble_uncertanties, test_labels, train_ensemble_predictions, train_ensemble_uncertanties, train_labels, results_saving_folder, num_bins=15)\n",
    "                \n",
    "                '''collecting the performance data from this model'''\n",
    "                # performance_data.append([15, fold_no, train_r2, test_r2, a, b, train_intercept, train_slope, CAL_train_intercept, CAL_train_slope, train_intercept, test_slope, CAL_test_intercept, CAL_test_slope, miscalibration_area, calibration_error])\n",
    "                performance_data.append([fold_no, train_r2, test_r2, miscalibration_area, calibration_error, sharpness, dispersion])\n",
    "\n",
    "            # columns = ['num bins', 'fold_no', 'train R2', 'test R2',  'a', 'b', 'train_intercept', 'train_slope', 'CAL_train_intercept', 'CAL_train_slope', 'train_intercept', 'test_slope', 'CAL_test_intercept', 'CAL_test_slope', 'miscal_area', 'cal_error']\n",
    "            columns = ['fold_no', 'train R2', 'test R2', 'miscal_area', 'cal_error', 'sharpness', 'dispersion']\n",
    "            df = pd.DataFrame(columns=columns)\n",
    "            for row in performance_data:\n",
    "                df.loc[len(df)] = row\n",
    "            average_row = df.mean()\n",
    "            df = df.append(average_row, ignore_index=True)\n",
    "                \n",
    "            results_saving_folder = f'{results_folder}/{label_to_predict}/{model_type}/{num_models}_models'\n",
    "            df.to_csv(results_saving_folder + f'/{label_to_predict}_{model_type}_{num_models}results.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
