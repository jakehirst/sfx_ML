{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forestci is an optional dependency. To install latest forestci compatabilty with scikit-learn>=0.24, run pip install git+git://github.com/scikit-learn-contrib/forest-confidence-interval.git\n",
      "XGBoost is an optional dependency. If you want to use XGBoost models, please manually install xgboost package with pip install xgboost. If have error with finding libxgboost.dylib library, dobrew install libomp. If do not have brew on your system, first do ruby -e \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)\" from the Terminal\n",
      "scikit-lego is an optional dependency, enabling use of the LowessRegression model. If you want to use this model, do \"pip install scikit-lego\"\n",
      "['init z', 'init y', 'init x', 'max_prop_speed', 'avg_prop_speed', 'dist btw frts', 'crack len', 'linearity', 'max thickness', 'mean thickness', 'median_thickness', 'var_thickness', 'std_thickness', 'thickness_at_init', 'max_kink', 'abs_val_mean_kink', 'mean_kink', 'sum_kink', 'abs_val_sum_kink', 'median_kink', 'std_kink', 'var_kink', 'avg_ori', 'angle_btw']\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "\n",
    "'''First, we need to define the path of where to get the dataset, and define other parameters that we will need'''\n",
    "import sys\n",
    "sys.path.append('/Users/jakehirst/Desktop/sfx/sfx_ML_code/sfx_ML/New_Models')\n",
    "\n",
    "from NN_fed_GPR import *\n",
    "from Bagging_models import *\n",
    "from Backward_feature_selection import *\n",
    "import ast\n",
    "\n",
    "model_types = ['Single RF', 'Single GPR', 'NN_fed_GPR']\n",
    "model_types = ['NN_fed_GPR']\n",
    "# model_types = ['Single GPR']\n",
    "\n",
    "all_labels = ['height', 'phi', 'theta', \n",
    "                            'impact site x', 'impact site y', 'impact site z', \n",
    "                            'impact site r', 'impact site phi', 'impact site theta']\n",
    "\n",
    "labels_to_predict = ['impact site x', 'impact site y', 'height']\n",
    "# labels_to_predict = ['height']\n",
    "\n",
    "with_or_without_transformations = 'with'\n",
    "with_or_without_transformations = 'without'\n",
    "\n",
    "Paper2_path = f'/Volumes/Jake_ssd/Paper 2/{with_or_without_transformations}_transformations'\n",
    "model_folder = Paper2_path + f'/UQ_bagging_models_{with_or_without_transformations}_transformations'\n",
    "data_folder = Paper2_path + '/5fold_datasets'\n",
    "results_folder = Paper2_path + '/Compare_Code_5_fold_ensemble_results'\n",
    "hyperparam_folder = Paper2_path + f'/bayesian_optimization_{with_or_without_transformations}_transformations'\n",
    "\n",
    "image_folder = '/Users/jakehirst/Desktop/sfx/sfx_ML_data/images_sfx/new_dataset/Visible_cracks'\n",
    "\n",
    "if(with_or_without_transformations == 'with'):\n",
    "    full_dataset_pathname = \"/Volumes/Jake_ssd/Paper 1/Paper_1_results_WITH_feature_engineering/dataset/feature_transformations_2023-11-16/height/HEIGHTALL_TRANSFORMED_FEATURES.csv\"\n",
    "    backward_feat_selection_results_folder = '/Volumes/Jake_ssd/Paper 1/Paper_1_results_WITH_feature_engineering/results'\n",
    "else:\n",
    "    full_dataset_pathname = \"/Volumes/Jake_ssd/Paper 1/Paper_1_results_no_feature_engineering/dataset/New_Crack_Len_FULL_OG_dataframe_2023_11_16.csv\"\n",
    "    backward_feat_selection_results_folder = Paper2_path + '/Paper_2_results_WITHOUT_feature_engineering/results' \n",
    "    df = pd.read_csv(full_dataset_pathname, index_col=0)\n",
    "    all_features = df.columns\n",
    "    all_features = all_features.drop(all_labels)\n",
    "    all_features = str(all_features.drop('timestep_init').to_list())\n",
    "\n",
    "    print(all_features)\n",
    "    \n",
    "    \n",
    "'''Only have to uncomment this if the 5 fold datasets have not been made or need to be remade'''\n",
    "# make_5_fold_datasets(data_folder, full_dataset_pathname, image_folder)\n",
    "\n",
    "print('ALL_TRANSFORMED_FEATURES' in full_dataset_pathname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using just the basic features\n",
      "using just the basic features\n",
      "using just the basic features\n",
      "{'impact site x': {'NN_fed_GPR': \"['init z', 'init y', 'init x', 'max_prop_speed', 'avg_prop_speed', 'dist btw frts', 'crack len', 'linearity', 'max thickness', 'mean thickness', 'median_thickness', 'var_thickness', 'std_thickness', 'thickness_at_init', 'max_kink', 'abs_val_mean_kink', 'mean_kink', 'sum_kink', 'abs_val_sum_kink', 'median_kink', 'std_kink', 'var_kink', 'avg_ori', 'angle_btw']\"}, 'impact site y': {'NN_fed_GPR': \"['init z', 'init y', 'init x', 'max_prop_speed', 'avg_prop_speed', 'dist btw frts', 'crack len', 'linearity', 'max thickness', 'mean thickness', 'median_thickness', 'var_thickness', 'std_thickness', 'thickness_at_init', 'max_kink', 'abs_val_mean_kink', 'mean_kink', 'sum_kink', 'abs_val_sum_kink', 'median_kink', 'std_kink', 'var_kink', 'avg_ori', 'angle_btw']\"}, 'height': {'NN_fed_GPR': \"['init z', 'init y', 'init x', 'max_prop_speed', 'avg_prop_speed', 'dist btw frts', 'crack len', 'linearity', 'max thickness', 'mean thickness', 'median_thickness', 'var_thickness', 'std_thickness', 'thickness_at_init', 'max_kink', 'abs_val_mean_kink', 'mean_kink', 'sum_kink', 'abs_val_sum_kink', 'median_kink', 'std_kink', 'var_kink', 'avg_ori', 'angle_btw']\"}}\n"
     ]
    }
   ],
   "source": [
    "'''get the appropriate features that each model will use based on backward feature elimination'''\n",
    "all_features_to_keep = {}\n",
    "\n",
    "min_features = 1 #minimum number of features you want to select from BFS (backward feature selection)\n",
    "max_features = 25 #maximum number of features you want to select from BFS\n",
    "for label in labels_to_predict:\n",
    "    all_features_to_keep[label] = {}\n",
    "    for model_type in model_types:\n",
    "        \n",
    "        if('ALL_TRANSFORMED_FEATURES' in full_dataset_pathname):\n",
    "            print('true')\n",
    "            model_type_hyperparam = model_type.removeprefix('Single ')\n",
    "            #TODO use code below if using feature selection\n",
    "            best_features = get_best_features(backward_feat_selection_results_folder, label, model_type_hyperparam, min_features, max_features)\n",
    "            all_features_to_keep[label][model_type] = best_features\n",
    "        \n",
    "        else:\n",
    "            print('using just the basic features')\n",
    "            #TODO use code below if NOT using feature selection\n",
    "            all_features_to_keep[label][model_type] = all_features\n",
    "\n",
    "print(all_features_to_keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\\ Predicting impact site x using NN_fed_GPR $$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "\n",
      "/Volumes/Jake_ssd/Paper 2/without_transformations/5fold_datasets/impact site x/fold1/train_features.csv\n",
      "['init z', 'init y', 'init x', 'max_prop_speed', 'avg_prop_speed', 'dist btw frts', 'crack len', 'linearity', 'max thickness', 'mean thickness', 'median_thickness', 'var_thickness', 'std_thickness', 'thickness_at_init', 'max_kink', 'abs_val_mean_kink', 'mean_kink', 'sum_kink', 'abs_val_sum_kink', 'median_kink', 'std_kink', 'var_kink', 'avg_ori', 'angle_btw']\n",
      "patience reached\n",
      "End train R2 score = 0.9660358073497062 validation R2 score = 0.7557039425567008\n",
      "\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\\ Predicting impact site y using NN_fed_GPR $$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "\n",
      "/Volumes/Jake_ssd/Paper 2/without_transformations/5fold_datasets/impact site y/fold1/train_features.csv\n",
      "['init z', 'init y', 'init x', 'max_prop_speed', 'avg_prop_speed', 'dist btw frts', 'crack len', 'linearity', 'max thickness', 'mean thickness', 'median_thickness', 'var_thickness', 'std_thickness', 'thickness_at_init', 'max_kink', 'abs_val_mean_kink', 'mean_kink', 'sum_kink', 'abs_val_sum_kink', 'median_kink', 'std_kink', 'var_kink', 'avg_ori', 'angle_btw']\n",
      "patience reached\n",
      "End train R2 score = 0.8586564126599415 validation R2 score = 0.37439338174357417\n",
      "\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\\ Predicting height using NN_fed_GPR $$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "\n",
      "/Volumes/Jake_ssd/Paper 2/without_transformations/5fold_datasets/height/fold1/train_features.csv\n",
      "['init z', 'init y', 'init x', 'max_prop_speed', 'avg_prop_speed', 'dist btw frts', 'crack len', 'linearity', 'max thickness', 'mean thickness', 'median_thickness', 'var_thickness', 'std_thickness', 'thickness_at_init', 'max_kink', 'abs_val_mean_kink', 'mean_kink', 'sum_kink', 'abs_val_sum_kink', 'median_kink', 'std_kink', 'var_kink', 'avg_ori', 'angle_btw']\n",
      "patience reached\n",
      "End train R2 score = 0.24608579767792427 validation R2 score = 0.047240978663656286\n",
      "\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\\ Predicting impact site x using NN_fed_GPR $$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "\n",
      "/Volumes/Jake_ssd/Paper 2/without_transformations/5fold_datasets/impact site x/fold2/train_features.csv\n",
      "['init z', 'init y', 'init x', 'max_prop_speed', 'avg_prop_speed', 'dist btw frts', 'crack len', 'linearity', 'max thickness', 'mean thickness', 'median_thickness', 'var_thickness', 'std_thickness', 'thickness_at_init', 'max_kink', 'abs_val_mean_kink', 'mean_kink', 'sum_kink', 'abs_val_sum_kink', 'median_kink', 'std_kink', 'var_kink', 'avg_ori', 'angle_btw']\n",
      "patience reached\n",
      "End train R2 score = 0.9751961581030407 validation R2 score = 0.6984533661474147\n",
      "\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\\ Predicting impact site y using NN_fed_GPR $$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "\n",
      "/Volumes/Jake_ssd/Paper 2/without_transformations/5fold_datasets/impact site y/fold2/train_features.csv\n",
      "['init z', 'init y', 'init x', 'max_prop_speed', 'avg_prop_speed', 'dist btw frts', 'crack len', 'linearity', 'max thickness', 'mean thickness', 'median_thickness', 'var_thickness', 'std_thickness', 'thickness_at_init', 'max_kink', 'abs_val_mean_kink', 'mean_kink', 'sum_kink', 'abs_val_sum_kink', 'median_kink', 'std_kink', 'var_kink', 'avg_ori', 'angle_btw']\n",
      "patience reached\n",
      "End train R2 score = 0.8293075495647895 validation R2 score = 0.3189959395006664\n",
      "\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\\ Predicting height using NN_fed_GPR $$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "\n",
      "/Volumes/Jake_ssd/Paper 2/without_transformations/5fold_datasets/height/fold2/train_features.csv\n",
      "['init z', 'init y', 'init x', 'max_prop_speed', 'avg_prop_speed', 'dist btw frts', 'crack len', 'linearity', 'max thickness', 'mean thickness', 'median_thickness', 'var_thickness', 'std_thickness', 'thickness_at_init', 'max_kink', 'abs_val_mean_kink', 'mean_kink', 'sum_kink', 'abs_val_sum_kink', 'median_kink', 'std_kink', 'var_kink', 'avg_ori', 'angle_btw']\n",
      "patience reached\n",
      "End train R2 score = 0.23662614169035479 validation R2 score = 0.05472955555743597\n",
      "\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\\ Predicting impact site x using NN_fed_GPR $$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "\n",
      "/Volumes/Jake_ssd/Paper 2/without_transformations/5fold_datasets/impact site x/fold3/train_features.csv\n",
      "['init z', 'init y', 'init x', 'max_prop_speed', 'avg_prop_speed', 'dist btw frts', 'crack len', 'linearity', 'max thickness', 'mean thickness', 'median_thickness', 'var_thickness', 'std_thickness', 'thickness_at_init', 'max_kink', 'abs_val_mean_kink', 'mean_kink', 'sum_kink', 'abs_val_sum_kink', 'median_kink', 'std_kink', 'var_kink', 'avg_ori', 'angle_btw']\n",
      "patience reached\n",
      "End train R2 score = 0.9456556745128464 validation R2 score = 0.667105593830648\n",
      "\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\\ Predicting impact site y using NN_fed_GPR $$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "\n",
      "/Volumes/Jake_ssd/Paper 2/without_transformations/5fold_datasets/impact site y/fold3/train_features.csv\n",
      "['init z', 'init y', 'init x', 'max_prop_speed', 'avg_prop_speed', 'dist btw frts', 'crack len', 'linearity', 'max thickness', 'mean thickness', 'median_thickness', 'var_thickness', 'std_thickness', 'thickness_at_init', 'max_kink', 'abs_val_mean_kink', 'mean_kink', 'sum_kink', 'abs_val_sum_kink', 'median_kink', 'std_kink', 'var_kink', 'avg_ori', 'angle_btw']\n",
      "patience reached\n",
      "End train R2 score = 0.9333645336970285 validation R2 score = 0.2187986471172343\n",
      "\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\\ Predicting height using NN_fed_GPR $$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "\n",
      "/Volumes/Jake_ssd/Paper 2/without_transformations/5fold_datasets/height/fold3/train_features.csv\n",
      "['init z', 'init y', 'init x', 'max_prop_speed', 'avg_prop_speed', 'dist btw frts', 'crack len', 'linearity', 'max thickness', 'mean thickness', 'median_thickness', 'var_thickness', 'std_thickness', 'thickness_at_init', 'max_kink', 'abs_val_mean_kink', 'mean_kink', 'sum_kink', 'abs_val_sum_kink', 'median_kink', 'std_kink', 'var_kink', 'avg_ori', 'angle_btw']\n",
      "patience reached\n",
      "End train R2 score = 0.19744768957108538 validation R2 score = 0.05319381682829072\n",
      "\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\\ Predicting impact site x using NN_fed_GPR $$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "\n",
      "/Volumes/Jake_ssd/Paper 2/without_transformations/5fold_datasets/impact site x/fold4/train_features.csv\n",
      "['init z', 'init y', 'init x', 'max_prop_speed', 'avg_prop_speed', 'dist btw frts', 'crack len', 'linearity', 'max thickness', 'mean thickness', 'median_thickness', 'var_thickness', 'std_thickness', 'thickness_at_init', 'max_kink', 'abs_val_mean_kink', 'mean_kink', 'sum_kink', 'abs_val_sum_kink', 'median_kink', 'std_kink', 'var_kink', 'avg_ori', 'angle_btw']\n",
      "patience reached\n",
      "End train R2 score = 0.9756387459962917 validation R2 score = 0.44737317834322576\n",
      "\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\\ Predicting impact site y using NN_fed_GPR $$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "\n",
      "/Volumes/Jake_ssd/Paper 2/without_transformations/5fold_datasets/impact site y/fold4/train_features.csv\n",
      "['init z', 'init y', 'init x', 'max_prop_speed', 'avg_prop_speed', 'dist btw frts', 'crack len', 'linearity', 'max thickness', 'mean thickness', 'median_thickness', 'var_thickness', 'std_thickness', 'thickness_at_init', 'max_kink', 'abs_val_mean_kink', 'mean_kink', 'sum_kink', 'abs_val_sum_kink', 'median_kink', 'std_kink', 'var_kink', 'avg_ori', 'angle_btw']\n",
      "patience reached\n",
      "End train R2 score = 0.9336029334953727 validation R2 score = 0.646215695877455\n",
      "\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\\ Predicting height using NN_fed_GPR $$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "\n",
      "/Volumes/Jake_ssd/Paper 2/without_transformations/5fold_datasets/height/fold4/train_features.csv\n",
      "['init z', 'init y', 'init x', 'max_prop_speed', 'avg_prop_speed', 'dist btw frts', 'crack len', 'linearity', 'max thickness', 'mean thickness', 'median_thickness', 'var_thickness', 'std_thickness', 'thickness_at_init', 'max_kink', 'abs_val_mean_kink', 'mean_kink', 'sum_kink', 'abs_val_sum_kink', 'median_kink', 'std_kink', 'var_kink', 'avg_ori', 'angle_btw']\n",
      "patience reached\n",
      "End train R2 score = 0.3181738762476455 validation R2 score = 0.12874585905642977\n",
      "\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\\ Predicting impact site x using NN_fed_GPR $$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "\n",
      "/Volumes/Jake_ssd/Paper 2/without_transformations/5fold_datasets/impact site x/fold5/train_features.csv\n",
      "['init z', 'init y', 'init x', 'max_prop_speed', 'avg_prop_speed', 'dist btw frts', 'crack len', 'linearity', 'max thickness', 'mean thickness', 'median_thickness', 'var_thickness', 'std_thickness', 'thickness_at_init', 'max_kink', 'abs_val_mean_kink', 'mean_kink', 'sum_kink', 'abs_val_sum_kink', 'median_kink', 'std_kink', 'var_kink', 'avg_ori', 'angle_btw']\n",
      "patience reached\n",
      "End train R2 score = 0.9483122913573233 validation R2 score = 0.7195510843056971\n",
      "\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\\ Predicting impact site y using NN_fed_GPR $$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "\n",
      "/Volumes/Jake_ssd/Paper 2/without_transformations/5fold_datasets/impact site y/fold5/train_features.csv\n",
      "['init z', 'init y', 'init x', 'max_prop_speed', 'avg_prop_speed', 'dist btw frts', 'crack len', 'linearity', 'max thickness', 'mean thickness', 'median_thickness', 'var_thickness', 'std_thickness', 'thickness_at_init', 'max_kink', 'abs_val_mean_kink', 'mean_kink', 'sum_kink', 'abs_val_sum_kink', 'median_kink', 'std_kink', 'var_kink', 'avg_ori', 'angle_btw']\n",
      "patience reached\n",
      "End train R2 score = 0.865030655468561 validation R2 score = 0.5150884102568036\n",
      "\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\\ Predicting height using NN_fed_GPR $$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "\n",
      "/Volumes/Jake_ssd/Paper 2/without_transformations/5fold_datasets/height/fold5/train_features.csv\n",
      "['init z', 'init y', 'init x', 'max_prop_speed', 'avg_prop_speed', 'dist btw frts', 'crack len', 'linearity', 'max thickness', 'mean thickness', 'median_thickness', 'var_thickness', 'std_thickness', 'thickness_at_init', 'max_kink', 'abs_val_mean_kink', 'mean_kink', 'sum_kink', 'abs_val_sum_kink', 'median_kink', 'std_kink', 'var_kink', 'avg_ori', 'angle_btw']\n",
      "patience reached\n",
      "End train R2 score = 0.21280365507888643 validation R2 score = 0.047388657980348414\n"
     ]
    }
   ],
   "source": [
    "'''Now we will make all of the models'''\n",
    "\n",
    "\n",
    "def make_UQ_model(training_features, training_labels, model_saving_folder, label_to_predict, num_models, features_to_keep, hyperparam_folder, num_training_points=False, model_type=None): \n",
    "    models = []\n",
    "    training_features = training_features[features_to_keep]\n",
    "    if(not os.path.exists(model_saving_folder)): os.mkdir(model_saving_folder)\n",
    "\n",
    "    if(model_type == 'Single RF'):\n",
    "        depth, features, samples_leaf, samples_split, estimators = get_best_hyperparameters_RF(label_to_predict=training_labels.columns[0], hyperparameter_folder=hyperparam_folder)\n",
    "        model =  RandomForestRegressor(max_depth=depth, max_features=features, \n",
    "                                       min_samples_leaf = samples_leaf, min_samples_split = samples_split, n_estimators=estimators, random_state=42)\n",
    "        model.fit(training_features, training_labels)\n",
    "        \n",
    "    elif(model_type == 'Single GPR'):\n",
    "        c, length_scale, noise_level = get_best_hyperparameters_GPR(label_to_predict=training_labels.columns[0], hyperparameter_folder=hyperparam_folder)\n",
    "        kernel = ConstantKernel(constant_value=c) * RBF(length_scale=length_scale) + WhiteKernel(noise_level=noise_level)\n",
    "        model = GaussianProcessRegressor(kernel=kernel, random_state=0, n_restarts_optimizer=25)\n",
    "        model.fit(training_features, training_labels)\n",
    "        \n",
    "    elif(model_type == 'NN_fed_GPR'):\n",
    "        # c, length_scale, noise_level = get_best_hyperparameters_NN_fed_GPR(label_to_predict=training_labels.columns[0], hyperparameter_folder=hyperparam_folder)\n",
    "        model = NN_fed_GPR()\n",
    "        model.fit(training_features, training_labels, hyperparam_folder)\n",
    "        \n",
    "    save_ensemble_model(model, 1, model_saving_folder) \n",
    "    \n",
    "    return \n",
    "\n",
    "\n",
    "\n",
    "for fold_no in range(1,6):\n",
    "    for model_type in model_types:\n",
    "        for label_to_predict in labels_to_predict:\n",
    "            print(f'\\n$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\\ Predicting {label_to_predict} using {model_type} $$$$$$$$$$$$$$$$$$$$$$$$$$$$$\\n')\n",
    "            \n",
    "            all_labels = ['height', 'phi', 'theta', \n",
    "                        'impact site x', 'impact site y', 'impact site z', \n",
    "                        'impact site r', 'impact site phi', 'impact site theta']\n",
    "\n",
    "            print(f'{data_folder}/{label_to_predict}/fold{fold_no}/train_features.csv')\n",
    "            training_features = pd.read_csv(f'{data_folder}/{label_to_predict}/fold{fold_no}/train_features.csv').reset_index(drop=True)\n",
    "            training_labels = pd.read_csv(f'{data_folder}/{label_to_predict}/fold{fold_no}/train_labels.csv').reset_index(drop=True)\n",
    "\n",
    "            model_saving_folder = f'{model_folder}/{label_to_predict}/{model_type}/1_models/fold_{fold_no}'\n",
    "            if(not os.path.exists(model_saving_folder)):\n",
    "                os.makedirs(model_saving_folder)\n",
    "                \n",
    "            results_saving_folder = f'{results_folder}/{label_to_predict}/{model_type}/1_models/fold_{fold_no}'\n",
    "            if(not os.path.exists(results_saving_folder)):\n",
    "                os.makedirs(results_saving_folder)\n",
    "            # make_dirs(model_saving_folder)\n",
    "            # make_dirs(results_saving_folder)\n",
    "\n",
    "            '''TODO gotta find out what features to use for each label before testing on new dataset'''\n",
    "            features_to_keep = ast.literal_eval(all_features_to_keep[label_to_predict][model_type])\n",
    "            print(features_to_keep)\n",
    "            make_UQ_model(training_features, training_labels, model_saving_folder, label_to_predict, 1, features_to_keep, hyperparam_folder, model_type=model_type)\n",
    "            # make_linear_regression_models_for_ensemble(training_features, training_labels, model_saving_folder, label_to_predict, num_models, features_to_keep, hyperparam_folder, model_type=model_type)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL TYPE = NN_fed_GPR\n",
      "LABEL = impact site x\n",
      "fold 1\n",
      "Calibration error = 0.59\n",
      "fold 2\n",
      "Calibration error = 0.33\n",
      "fold 3\n",
      "Calibration error = 0.28\n",
      "fold 4\n",
      "Calibration error = 0.28\n",
      "fold 5\n",
      "Calibration error = 0.28\n",
      "LABEL = impact site y\n",
      "fold 1\n",
      "Calibration error = 0.97\n",
      "fold 2\n",
      "Calibration error = 0.82\n",
      "fold 3\n",
      "Calibration error = 0.20\n",
      "fold 4\n",
      "Calibration error = 0.30\n",
      "fold 5\n",
      "Calibration error = 0.27\n",
      "LABEL = height\n",
      "fold 1\n",
      "Calibration error = 0.33\n",
      "fold 2\n",
      "Calibration error = 0.08\n",
      "fold 3\n",
      "Calibration error = 0.11\n",
      "fold 4\n",
      "Calibration error = 0.16\n",
      "fold 5\n",
      "Calibration error = 0.29\n"
     ]
    }
   ],
   "source": [
    "\n",
    "'''\n",
    "Helper function predicts the labels of the featureset given, and the uncertainty.\n",
    "Also compares this to the true labels of the dataset.\n",
    "'''\n",
    "def Get_predictions_and_uncertainty(test_features_path, test_labels_path, model_folder, saving_folder, features_to_keep, label_to_predict, model_type):\n",
    "    if(not os.path.exists(saving_folder)): os.makedirs(saving_folder)\n",
    "    test_features = pd.read_csv(test_features_path)[features_to_keep]\n",
    "    test_labels = pd.read_csv(test_labels_path) \n",
    "\n",
    "    filename = model_folder + '/model_no1.sav'\n",
    "    with open(os.path.join(model_folder, filename), 'rb') as file:\n",
    "        model = pickle.load(file)\n",
    "    \n",
    "    # Loop through the pickle files in the folder\n",
    "    # for filename in os.listdir(model_folder):\n",
    "    #     if filename.endswith('.sav'):\n",
    "    #         # Load the model from the pickle file\n",
    "    #         with open(os.path.join(model_folder, filename), 'rb') as file:\n",
    "    #             model = pickle.load(file)\n",
    "    #             models.append(model)\n",
    "    \n",
    "    all_model_predictions = []\n",
    "    # for model in models:\n",
    "    if(model_type == 'Single RF'): \n",
    "        \n",
    "        tree_predictions = []\n",
    "        # Iterate over all trees in the random forest\n",
    "        for tree in model.estimators_:\n",
    "            # Predict using the current tree\n",
    "            tree_pred = tree.predict(test_features.to_numpy())\n",
    "            # Append the predictions to the list\n",
    "            tree_predictions.append(tree_pred)\n",
    "\n",
    "        # Convert the list to a NumPy array for easier manipulation if needed\n",
    "        tree_predictions = np.array(tree_predictions)\n",
    "        \n",
    "        # current_predictions = model.predict(test_features.to_numpy()) #COMMENT this is the same as the average of all the individual trees\n",
    "        current_predictions = np.mean(tree_predictions, axis=0)\n",
    "        single_pred_stds = np.std(tree_predictions, axis=0)\n",
    "        \n",
    "    elif(model_type == 'Single GPR'):\n",
    "        current_predictions, single_pred_stds = model.predict(test_features.to_numpy(), return_std=True)\n",
    "        # current_predictions = model.predict(test_features.to_numpy())\n",
    "            \n",
    "        # current_predictions = model.predict(test_features.to_numpy())\n",
    "        current_predictions = current_predictions.reshape(current_predictions.shape[0])\n",
    "        all_model_predictions.append(current_predictions)\n",
    "    \n",
    "    elif(model_type == 'NN_fed_GPR'):\n",
    "        current_predictions, single_pred_stds = model.predict(test_features.to_numpy())\n",
    "        # current_predictions = model.predict(test_features.to_numpy())\n",
    "            \n",
    "        # current_predictions = model.predict(test_features.to_numpy())\n",
    "        current_predictions = current_predictions.reshape(current_predictions.shape[0])\n",
    "        all_model_predictions.append(current_predictions)\n",
    "\n",
    "    all_model_predictions = np.array(all_model_predictions)\n",
    "    \n",
    "    # ensemble_predictions = []\n",
    "    # ensemble_uncertanties = []\n",
    "    # for label_no in range(len(test_labels)):\n",
    "    #     true_label = test_labels.iloc[label_no][0]\n",
    "    #     mean_prediction, std_prediction = np.mean(all_model_predictions[:, label_no]), np.std(all_model_predictions[:, label_no])\n",
    "    #     ensemble_predictions.append(mean_prediction)\n",
    "    #     ensemble_uncertanties.append(std_prediction*2) #uncertainty will be 2 * the std of the predictions\n",
    "    \n",
    "    uncertainties = single_pred_stds * 2\n",
    "    test_or_train = test_features_path.split('_')[-2].split('/')[-1]\n",
    "    r2 = parody_plot_with_std(test_labels.to_numpy(), current_predictions, uncertainties, saving_folder, label_to_predict, model_type, testtrain=test_or_train)\n",
    "    \n",
    "    return r2, current_predictions, uncertainties, test_labels\n",
    "\n",
    "\n",
    "'''Now we will evaluate the performance of the bagging models'''\n",
    "\n",
    "for model_type in model_types:\n",
    "    print(f'MODEL TYPE = {model_type}')\n",
    "    for label_to_predict in labels_to_predict:\n",
    "        print(f'LABEL = {label_to_predict}')\n",
    "        performance_data = []\n",
    "        for fold_no in range(1,6):\n",
    "            print(f'fold {fold_no}')\n",
    "            \n",
    "            #defining folders to get the models and to store the results\n",
    "            model_saving_folder = f'{model_folder}/{label_to_predict}/{model_type}/1_models/fold_{fold_no}'\n",
    "            results_saving_folder = f'{results_folder}/{label_to_predict}/{model_type}/1_models/fold_{fold_no}'\n",
    "            \n",
    "            #defining folders where the datasets are coming from (5-fold cv)\n",
    "            test_features_path = Paper2_path + f'/5fold_datasets/{label_to_predict}/fold{fold_no}/test_features.csv'\n",
    "            test_labels_path = Paper2_path + f'/5fold_datasets/{label_to_predict}/fold{fold_no}/test_labels.csv'\n",
    "            train_features_path = Paper2_path + f'/5fold_datasets/{label_to_predict}/fold{fold_no}/train_features.csv'\n",
    "            train_labels_path = Paper2_path + f'/5fold_datasets/{label_to_predict}/fold{fold_no}/train_labels.csv'\n",
    "\n",
    "            #defining the features that each model used (since they vary with each model)\n",
    "            features_to_keep = ast.literal_eval(all_features_to_keep[label_to_predict][model_type])\n",
    "            \n",
    "            #predicting the test and train sets with the bagging models\n",
    "            test_r2, test_ensemble_predictions, test_ensemble_uncertanties, test_labels = Get_predictions_and_uncertainty(test_features_path, test_labels_path, model_saving_folder, results_saving_folder, features_to_keep, label_to_predict, model_type)\n",
    "            train_r2, train_ensemble_predictions, train_ensemble_uncertanties, train_labels = Get_predictions_and_uncertainty(train_features_path, train_labels_path, model_saving_folder, results_saving_folder, features_to_keep, label_to_predict, model_type)\n",
    "\n",
    "            #defining the residual errors of the predictions\n",
    "            train_labels_arr = train_labels.to_numpy().T[0]\n",
    "            train_predictions_arr = np.array(train_ensemble_predictions)\n",
    "            test_labels_arr = test_labels.to_numpy().T[0]\n",
    "            test_predictions_arr = np.array(test_ensemble_predictions)\n",
    "            train_residuals = pd.Series(np.abs(train_labels_arr - train_predictions_arr))\n",
    "            test_residuals = pd.Series(np.abs(test_labels_arr - test_predictions_arr))\n",
    "\n",
    "            a = 0\n",
    "            b = 0\n",
    "            '''getting calibration factors *** linear'''\n",
    "            # cf = CorrectionFactors(train_residuals, pd.Series(train_ensemble_uncertanties))\n",
    "            # a, b = cf.nll()\n",
    "            # print(f'a = {a} b = {b}')\n",
    "            # calibrated_train_uncertainties = pd.Series(a * np.array(train_ensemble_uncertanties) + b, name='train_model_errors')\n",
    "            # calibrated_test_uncertainties = pd.Series(a * np.array(test_ensemble_uncertanties) + b, name='test_model_errors')\n",
    "            \n",
    "            '''getting calibration factors *** Nonlinear'''\n",
    "            # a, b = get_calibration_factors(train_residuals, train_ensemble_uncertanties)\n",
    "            # print(f'a = {a} b = {b}')\n",
    "            # calibrated_train_uncertainties = pd.Series(a * (train_ensemble_uncertanties**((b/2) + 1)), name='train_model_errors')\n",
    "            # calibrated_test_uncertainties = pd.Series(a * (test_ensemble_uncertanties**((b/2) + 1)), name='test_model_errors')\n",
    "\n",
    "            '''\n",
    "            Calculating and plotting performance metrics as outlined in section 2.3 of Tran et al. (https://dx.doi.org/10.1088/2632-2153/ab7e1a)\n",
    "            \n",
    "            Models should be compared in terms of \n",
    "            1st - accuracy (R^2) \n",
    "            2nd - calibration (miscalibration area)\n",
    "            3rd - sharpness\n",
    "            4th - dispersion\n",
    "            '''\n",
    "            #CALIBRATION plots and miscalibration area\n",
    "            #This tells us how 'honest' our uncertainty values are. A perfect calibration plot would mean for a given confidence interval in our prediction\n",
    "            #(say 90%), we can expect with 90% certainty that the true value falls within that confidence interval.\n",
    "            miscalibration_area, calibration_error = make_calibration_plots(model_type, test_predictions_arr, test_labels_arr, test_ensemble_uncertanties, results_saving_folder)\n",
    "            #SHARPNESS plots and value\n",
    "            #Models can be calibrated, but all have very dull uncertainty values (they all have large uncertainties). To ensure UQ is meaningful, models\n",
    "            #should a be sharp (i.e. uncertainties should be as small as possible.)\n",
    "            #Sharpness is essentially calculated as the average of predicted standard deviations. #COMMENT Low sharpness values are better.\n",
    "            stdevs = np.array(test_ensemble_uncertanties)/2 #right now, i multiply the stds by 2 to make it look better in parity plots... but this needs the raw std.\n",
    "            sharpness, dispersion = plot_sharpness_curve(stdevs, results_saving_folder)\n",
    "            #DISPERSION value\n",
    "            #Models can be calibrated and sharp, but even so, if they are all similar uncertainties, then this does not tell us much. To ensure more \n",
    "            #meaningful UQ, having a large dispersion of uncertainties is valuable. \n",
    "            #Dispersion is calculated using equation 4 of the paper, which is called the coefficient of variation (Cv). #COMMENT High dispersion (Cv) values are better.\n",
    "                \n",
    "            \n",
    "            # blank_model_for_plot = SklearnModel('RandomForestRegressor')\n",
    "            # mastml_RVE = Error()\n",
    "\n",
    "            # mastml_RVE.plot_real_vs_predicted_error_uncal_cal_overlay(savepath=results_saving_folder, \n",
    "            #                                                         model=blank_model_for_plot, \n",
    "            #                                                         data_type='train', \n",
    "            #                                                         model_errors=pd.Series(train_ensemble_uncertanties) ,\n",
    "            #                                                         model_errors_cal= calibrated_train_uncertainties,\n",
    "            #                                                         residuals= train_residuals, \n",
    "            #                                                         dataset_stdev=np.std(train_labels.to_numpy()), \n",
    "            #                                                         show_figure=False,\n",
    "            #                                                         well_sampled_number=0.025)\n",
    "            \n",
    "            \n",
    "            # mastml_RVE.plot_real_vs_predicted_error_uncal_cal_overlay(savepath=results_saving_folder, \n",
    "            #                                                         model=blank_model_for_plot, \n",
    "            #                                                         data_type='test', \n",
    "            #                                                         model_errors=pd.Series(test_ensemble_uncertanties) ,\n",
    "            #                                                         model_errors_cal= calibrated_test_uncertainties,\n",
    "            #                                                         residuals= test_residuals, \n",
    "            #                                                         dataset_stdev=np.std(train_labels.to_numpy()), \n",
    "            #                                                         show_figure=False,\n",
    "            #                                                         well_sampled_number=0.025)\n",
    "            \n",
    "            '''using their library to make an rve plot'''\n",
    "            # train_intercept, train_slope, CAL_train_intercept, CAL_train_slope, train_intercept, test_slope, CAL_test_intercept, CAL_test_slope = make_RVE_plots(label_to_predict, model_type, test_ensemble_predictions, test_ensemble_uncertanties, test_labels, train_ensemble_predictions, train_ensemble_uncertanties, train_labels, results_saving_folder, num_bins=15)\n",
    "            \n",
    "            '''collecting the performance data from this model'''\n",
    "            # performance_data.append([15, fold_no, train_r2, test_r2, a, b, train_intercept, train_slope, CAL_train_intercept, CAL_train_slope, train_intercept, test_slope, CAL_test_intercept, CAL_test_slope, miscalibration_area, calibration_error])\n",
    "            performance_data.append([fold_no, train_r2, test_r2, miscalibration_area, calibration_error, sharpness, dispersion])\n",
    "            \n",
    "        # columns = ['num bins', 'fold_no', 'train R2', 'test R2',  'a', 'b', 'train_intercept', 'train_slope', 'CAL_train_intercept', 'CAL_train_slope', 'train_intercept', 'test_slope', 'CAL_test_intercept', 'CAL_test_slope', 'miscal_area', 'cal_error']\n",
    "        columns = ['fold_no', 'train R2', 'test R2', 'miscal_area', 'cal_error', 'sharpness', 'dispersion']\n",
    "        df = pd.DataFrame(columns=columns)\n",
    "        for row in performance_data:\n",
    "            df.loc[len(df)] = row\n",
    "        average_row = df.mean()\n",
    "        df = df.append(average_row, ignore_index=True)\n",
    "            \n",
    "        results_saving_folder = f'{results_folder}/{label_to_predict}/{model_type}/1_models'\n",
    "        df.to_csv(results_saving_folder + f'/{label_to_predict}_{model_type}_1results.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
