{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook runs the code in bagging_models.py for uncertainty quantification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forestci is an optional dependency. To install latest forestci compatabilty with scikit-learn>=0.24, run pip install git+git://github.com/scikit-learn-contrib/forest-confidence-interval.git\n",
      "XGBoost is an optional dependency. If you want to use XGBoost models, please manually install xgboost package with pip install xgboost. If have error with finding libxgboost.dylib library, dobrew install libomp. If do not have brew on your system, first do ruby -e \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)\" from the Terminal\n",
      "scikit-lego is an optional dependency, enabling use of the LowessRegression model. If you want to use this model, do \"pip install scikit-lego\"\n",
      "['init z', 'init y', 'init x', 'max_prop_speed', 'avg_prop_speed', 'dist btw frts', 'crack len', 'linearity', 'max thickness', 'mean thickness', 'median_thickness', 'var_thickness', 'std_thickness', 'thickness_at_init', 'max_kink', 'abs_val_mean_kink', 'mean_kink', 'sum_kink', 'abs_val_sum_kink', 'median_kink', 'std_kink', 'var_kink', 'avg_ori', 'angle_btw']\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "'''First, we need to define the path of where to get the dataset, and define other parameters that we will need'''\n",
    "from Bagging_models import *\n",
    "from Backward_feature_selection import *\n",
    "import ast\n",
    "\n",
    "model_types = ['ANN', 'RF', 'GPR','ridge']\n",
    "# model_types = ['GPR']\n",
    "all_labels = ['height', 'phi', 'theta', \n",
    "                            'impact site x', 'impact site y', 'impact site z', \n",
    "                            'impact site r', 'impact site phi', 'impact site theta']\n",
    "\n",
    "num_models_list = [20]\n",
    "labels_to_predict = ['impact site x', 'impact site y', 'height']\n",
    "# labels_to_predict = ['impact site x']\n",
    "\n",
    "with_or_without_transformations = 'with'\n",
    "with_or_without_transformations = 'without'\n",
    "\n",
    "Paper2_path = f'/Volumes/Jake_ssd/Paper 2/{with_or_without_transformations}_transformations'\n",
    "model_folder = Paper2_path + f'/UQ_bagging_models_{with_or_without_transformations}_transformations'\n",
    "data_folder = Paper2_path + '/5fold_datasets'\n",
    "results_folder = Paper2_path + '/Compare_Code_5_fold_ensemble_results'\n",
    "hyperparam_folder = Paper2_path + f'/bayesian_optimization_{with_or_without_transformations}_transformations'\n",
    "\n",
    "\n",
    "image_folder = '/Users/jakehirst/Desktop/sfx/sfx_ML_data/images_sfx/new_dataset/Visible_cracks'\n",
    "\n",
    "if(with_or_without_transformations == 'with'):\n",
    "    full_dataset_pathname = \"/Volumes/Jake_ssd/Paper_1_results_WITH_feature_engineering/dataset/feature_transformations_2023-11-16/height/HEIGHTALL_TRANSFORMED_FEATURES.csv\"\n",
    "    backward_feat_selection_results_folder = '/Volumes/Jake_ssd/Paper_1_results_WITH_feature_engineering/results'\n",
    "else:\n",
    "    full_dataset_pathname = \"/Volumes/Jake_ssd/Paper_1_results_no_feature_engineering/dataset/New_Crack_Len_FULL_OG_dataframe_2023_11_16.csv\"\n",
    "    backward_feat_selection_results_folder = Paper2_path + '/Paper_2_results_WITHOUT_feature_engineering/results' \n",
    "    df = pd.read_csv(full_dataset_pathname, index_col=0)\n",
    "    all_features = df.columns\n",
    "    all_features = all_features.drop(all_labels)\n",
    "    all_features = str(all_features.drop('timestep_init').to_list())\n",
    "\n",
    "    print(all_features)\n",
    " \n",
    "\n",
    "\n",
    "'''Only have to uncomment this if the 5 fold datasets have not been made or need to be remade'''\n",
    "# make_5_fold_datasets(data_folder, full_dataset_pathname, image_folder)\n",
    "\n",
    "\n",
    "print('ALL_TRANSFORMED_FEATURES' in full_dataset_pathname)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using just the basic features\n",
      "using just the basic features\n",
      "using just the basic features\n",
      "using just the basic features\n",
      "using just the basic features\n",
      "using just the basic features\n",
      "using just the basic features\n",
      "using just the basic features\n",
      "using just the basic features\n",
      "using just the basic features\n",
      "using just the basic features\n",
      "using just the basic features\n",
      "{'impact site x': {'ANN': \"['init z', 'init y', 'init x', 'max_prop_speed', 'avg_prop_speed', 'dist btw frts', 'crack len', 'linearity', 'max thickness', 'mean thickness', 'median_thickness', 'var_thickness', 'std_thickness', 'thickness_at_init', 'max_kink', 'abs_val_mean_kink', 'mean_kink', 'sum_kink', 'abs_val_sum_kink', 'median_kink', 'std_kink', 'var_kink', 'avg_ori', 'angle_btw']\", 'RF': \"['init z', 'init y', 'init x', 'max_prop_speed', 'avg_prop_speed', 'dist btw frts', 'crack len', 'linearity', 'max thickness', 'mean thickness', 'median_thickness', 'var_thickness', 'std_thickness', 'thickness_at_init', 'max_kink', 'abs_val_mean_kink', 'mean_kink', 'sum_kink', 'abs_val_sum_kink', 'median_kink', 'std_kink', 'var_kink', 'avg_ori', 'angle_btw']\", 'GPR': \"['init z', 'init y', 'init x', 'max_prop_speed', 'avg_prop_speed', 'dist btw frts', 'crack len', 'linearity', 'max thickness', 'mean thickness', 'median_thickness', 'var_thickness', 'std_thickness', 'thickness_at_init', 'max_kink', 'abs_val_mean_kink', 'mean_kink', 'sum_kink', 'abs_val_sum_kink', 'median_kink', 'std_kink', 'var_kink', 'avg_ori', 'angle_btw']\", 'ridge': \"['init z', 'init y', 'init x', 'max_prop_speed', 'avg_prop_speed', 'dist btw frts', 'crack len', 'linearity', 'max thickness', 'mean thickness', 'median_thickness', 'var_thickness', 'std_thickness', 'thickness_at_init', 'max_kink', 'abs_val_mean_kink', 'mean_kink', 'sum_kink', 'abs_val_sum_kink', 'median_kink', 'std_kink', 'var_kink', 'avg_ori', 'angle_btw']\"}, 'impact site y': {'ANN': \"['init z', 'init y', 'init x', 'max_prop_speed', 'avg_prop_speed', 'dist btw frts', 'crack len', 'linearity', 'max thickness', 'mean thickness', 'median_thickness', 'var_thickness', 'std_thickness', 'thickness_at_init', 'max_kink', 'abs_val_mean_kink', 'mean_kink', 'sum_kink', 'abs_val_sum_kink', 'median_kink', 'std_kink', 'var_kink', 'avg_ori', 'angle_btw']\", 'RF': \"['init z', 'init y', 'init x', 'max_prop_speed', 'avg_prop_speed', 'dist btw frts', 'crack len', 'linearity', 'max thickness', 'mean thickness', 'median_thickness', 'var_thickness', 'std_thickness', 'thickness_at_init', 'max_kink', 'abs_val_mean_kink', 'mean_kink', 'sum_kink', 'abs_val_sum_kink', 'median_kink', 'std_kink', 'var_kink', 'avg_ori', 'angle_btw']\", 'GPR': \"['init z', 'init y', 'init x', 'max_prop_speed', 'avg_prop_speed', 'dist btw frts', 'crack len', 'linearity', 'max thickness', 'mean thickness', 'median_thickness', 'var_thickness', 'std_thickness', 'thickness_at_init', 'max_kink', 'abs_val_mean_kink', 'mean_kink', 'sum_kink', 'abs_val_sum_kink', 'median_kink', 'std_kink', 'var_kink', 'avg_ori', 'angle_btw']\", 'ridge': \"['init z', 'init y', 'init x', 'max_prop_speed', 'avg_prop_speed', 'dist btw frts', 'crack len', 'linearity', 'max thickness', 'mean thickness', 'median_thickness', 'var_thickness', 'std_thickness', 'thickness_at_init', 'max_kink', 'abs_val_mean_kink', 'mean_kink', 'sum_kink', 'abs_val_sum_kink', 'median_kink', 'std_kink', 'var_kink', 'avg_ori', 'angle_btw']\"}, 'height': {'ANN': \"['init z', 'init y', 'init x', 'max_prop_speed', 'avg_prop_speed', 'dist btw frts', 'crack len', 'linearity', 'max thickness', 'mean thickness', 'median_thickness', 'var_thickness', 'std_thickness', 'thickness_at_init', 'max_kink', 'abs_val_mean_kink', 'mean_kink', 'sum_kink', 'abs_val_sum_kink', 'median_kink', 'std_kink', 'var_kink', 'avg_ori', 'angle_btw']\", 'RF': \"['init z', 'init y', 'init x', 'max_prop_speed', 'avg_prop_speed', 'dist btw frts', 'crack len', 'linearity', 'max thickness', 'mean thickness', 'median_thickness', 'var_thickness', 'std_thickness', 'thickness_at_init', 'max_kink', 'abs_val_mean_kink', 'mean_kink', 'sum_kink', 'abs_val_sum_kink', 'median_kink', 'std_kink', 'var_kink', 'avg_ori', 'angle_btw']\", 'GPR': \"['init z', 'init y', 'init x', 'max_prop_speed', 'avg_prop_speed', 'dist btw frts', 'crack len', 'linearity', 'max thickness', 'mean thickness', 'median_thickness', 'var_thickness', 'std_thickness', 'thickness_at_init', 'max_kink', 'abs_val_mean_kink', 'mean_kink', 'sum_kink', 'abs_val_sum_kink', 'median_kink', 'std_kink', 'var_kink', 'avg_ori', 'angle_btw']\", 'ridge': \"['init z', 'init y', 'init x', 'max_prop_speed', 'avg_prop_speed', 'dist btw frts', 'crack len', 'linearity', 'max thickness', 'mean thickness', 'median_thickness', 'var_thickness', 'std_thickness', 'thickness_at_init', 'max_kink', 'abs_val_mean_kink', 'mean_kink', 'sum_kink', 'abs_val_sum_kink', 'median_kink', 'std_kink', 'var_kink', 'avg_ori', 'angle_btw']\"}}\n"
     ]
    }
   ],
   "source": [
    "'''get the appropriate features that each model will use based on backward feature elimination'''\n",
    "all_features_to_keep = {}\n",
    "\n",
    "min_features = 1 #minimum number of features you want to select from BFS (backward feature selection)\n",
    "max_features = 25 #maximum number of features you want to select from BFS\n",
    "for label in labels_to_predict:\n",
    "    all_features_to_keep[label] = {}\n",
    "    for model_type in model_types:\n",
    "        \n",
    "        if('ALL_TRANSFORMED_FEATURES' in full_dataset_pathname):\n",
    "            print('true')\n",
    "        #TODO use code below if using feature selection\n",
    "            best_features = get_best_features(backward_feat_selection_results_folder, label, model_type, min_features, max_features)\n",
    "            all_features_to_keep[label][model_type] = best_features\n",
    "        \n",
    "        else:\n",
    "            print('using just the basic features')\n",
    "            #TODO use code below if NOT using feature selection\n",
    "            all_features_to_keep[label][model_type] = all_features\n",
    "\n",
    "print(all_features_to_keep)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Now we will make all of the bagging models'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Now we will make all of the bagging models'''\n",
    "# for fold_no in range(1,6):\n",
    "#     for model_type in model_types:\n",
    "#         for label_to_predict in labels_to_predict:\n",
    "#             for num_models in num_models_list:\n",
    "                \n",
    "#                 print(f'\\n$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\\ Predicting {label_to_predict} using {model_type} $$$$$$$$$$$$$$$$$$$$$$$$$$$$$\\n')\n",
    "                \n",
    "#                 all_labels = ['height', 'phi', 'theta', \n",
    "#                             'impact site x', 'impact site y', 'impact site z', \n",
    "#                             'impact site r', 'impact site phi', 'impact site theta']\n",
    "\n",
    "#                 print(f'{data_folder}/{label_to_predict}/fold{fold_no}/train_features.csv')\n",
    "#                 training_features = pd.read_csv(f'{data_folder}/{label_to_predict}/fold{fold_no}/train_features.csv').reset_index(drop=True)\n",
    "#                 training_labels = pd.read_csv(f'{data_folder}/{label_to_predict}/fold{fold_no}/train_labels.csv').reset_index(drop=True)\n",
    "\n",
    "#                 model_saving_folder = f'{model_folder}/{label_to_predict}/{model_type}/{num_models}_models/fold_{fold_no}'\n",
    "#                 if(not os.path.exists(model_saving_folder)):\n",
    "#                     os.makedirs(model_saving_folder)\n",
    "                    \n",
    "#                 results_saving_folder = f'{results_folder}/{label_to_predict}/{model_type}/{num_models}_models/fold_{fold_no}'\n",
    "#                 if(not os.path.exists(results_saving_folder)):\n",
    "#                     os.makedirs(results_saving_folder)\n",
    "#                 # make_dirs(model_saving_folder)\n",
    "#                 # make_dirs(results_saving_folder)\n",
    "\n",
    "#                 '''TODO gotta find out what features to use for each label before testing on new dataset'''\n",
    "#                 features_to_keep = ast.literal_eval(all_features_to_keep[label_to_predict][model_type])\n",
    "#                 print(features_to_keep)\n",
    "#                 make_linear_regression_models_for_ensemble(training_features, training_labels, model_saving_folder, label_to_predict, num_models, features_to_keep, hyperparam_folder, model_type=model_type)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL TYPE = ANN\n",
      "LABEL = impact site x\n",
      "fold 1\n",
      "a = 0.3401153994861077 b = 0.17277491426891747\n",
      "Calibration error = 0.92\n",
      "fold 2\n",
      "a = 0.3581162994878465 b = 0.1778755286190326\n",
      "Calibration error = 0.38\n",
      "fold 3\n",
      "a = 0.3696079762626132 b = -0.007696537446578611\n",
      "Calibration error = 0.58\n",
      "fold 4\n",
      "a = 0.25391507704639416 b = 1.3039349211028033\n",
      "Calibration error = 1.07\n",
      "fold 5\n",
      "a = 0.4179315266179387 b = -0.2894347119507761\n",
      "Calibration error = 0.62\n",
      "LABEL = impact site y\n",
      "fold 1\n",
      "a = 0.46752396055280876 b = 0.8460975899488999\n",
      "Calibration error = 2.09\n",
      "fold 2\n",
      "a = 0.5574546724557865 b = 0.0005459976829588416\n",
      "Calibration error = 2.34\n",
      "fold 3\n",
      "a = 0.48855738410099914 b = 0.12657263567819627\n",
      "Calibration error = 0.87\n",
      "fold 4\n",
      "a = 0.5167990680160452 b = 0.1501376075515099\n",
      "Calibration error = 0.77\n",
      "fold 5\n",
      "a = 0.5630443417702785 b = -0.11462537203787704\n",
      "Calibration error = 1.43\n",
      "LABEL = height\n",
      "fold 1\n",
      "a = 0.24185947791676413 b = 0.6895542624760596\n",
      "Calibration error = 2.73\n",
      "fold 2\n",
      "a = -0.007628381763646273 b = 0.9116086132953805\n",
      "Calibration error = 1.93\n",
      "fold 3\n",
      "a = 0.18949329289260855 b = 0.7354515328827806\n",
      "Calibration error = 3.15\n",
      "fold 4\n",
      "a = -0.045845498669736154 b = 0.9219680844696232\n",
      "Calibration error = 2.81\n",
      "fold 5\n",
      "a = 0.2781871090928847 b = 0.6763239188320269\n",
      "Calibration error = 3.04\n",
      "MODEL TYPE = RF\n",
      "LABEL = impact site x\n",
      "fold 1\n",
      "a = 0.8985187092066353 b = -0.249594750683403\n",
      "Calibration error = 3.97\n",
      "fold 2\n",
      "a = 0.920446144123056 b = -0.23350157347785497\n",
      "Calibration error = 2.91\n",
      "fold 3\n",
      "a = 0.8336926383331491 b = 0.01816410679974413\n",
      "Calibration error = 2.74\n",
      "fold 4\n",
      "a = 0.8806511612154663 b = -0.2677214787455113\n",
      "Calibration error = 4.41\n",
      "fold 5\n",
      "a = 0.908924978698153 b = -0.4399058541489429\n",
      "Calibration error = 2.88\n",
      "LABEL = impact site y\n",
      "fold 1\n",
      "a = 0.974389021636702 b = -0.5101361335354837\n",
      "Calibration error = 5.66\n",
      "fold 2\n",
      "Warning: NLL optimization failed!\n",
      "a = 0.8540313720703205 b = -0.010456615447998006\n",
      "Calibration error = 6.52\n",
      "fold 3\n",
      "a = 0.9198091846672887 b = -0.33140942001399426\n",
      "Calibration error = 3.77\n",
      "fold 4\n",
      "a = 0.9802270822445449 b = -0.6248304676906071\n",
      "Calibration error = 3.36\n",
      "fold 5\n",
      "a = 0.9458739650796525 b = -0.5178936803114578\n",
      "Calibration error = 6.01\n",
      "LABEL = height\n",
      "fold 1\n",
      "a = 1.2291126622485509 b = -0.10541892608287487\n",
      "Calibration error = 5.08\n",
      "fold 2\n",
      "a = 1.3473623602791294 b = -0.17456400484057621\n",
      "Calibration error = 3.41\n",
      "fold 3\n",
      "a = 1.3749882815194836 b = -0.16824828307179684\n",
      "Calibration error = 4.18\n",
      "fold 4\n",
      "a = 1.2493624769201876 b = -0.10408979586559086\n",
      "Calibration error = 4.95\n",
      "fold 5\n",
      "a = 1.300104084216444 b = -0.12554052857216408\n",
      "Calibration error = 5.13\n",
      "MODEL TYPE = GPR\n",
      "LABEL = impact site x\n",
      "fold 1\n",
      "a = 0.3682891804142838 b = -0.00011325601385033169\n",
      "Calibration error = 8.97\n",
      "fold 2\n",
      "a = 0.3739489111418761 b = 0.032462248761485735\n",
      "Calibration error = 5.78\n",
      "fold 3\n",
      "a = 0.34475106310008785 b = 0.020718217830206994\n",
      "Calibration error = 5.79\n",
      "fold 4\n",
      "a = 0.35519731375155594 b = 0.02626907741609121\n",
      "Calibration error = 7.51\n",
      "fold 5\n",
      "a = 0.36194685942027527 b = 0.0011114719644247095\n",
      "Calibration error = 6.73\n",
      "LABEL = impact site y\n",
      "fold 1\n",
      "a = 0.3457255651577442 b = 0.05355572537277388\n",
      "Calibration error = 5.55\n",
      "fold 2\n",
      "a = 0.35285374444391415 b = 0.14413656357678106\n",
      "Calibration error = 7.99\n",
      "fold 3\n",
      "a = 0.3843086699778497 b = -0.24113727057957468\n",
      "Calibration error = 5.04\n",
      "fold 4\n",
      "a = 0.37047758397100394 b = -0.2848504837007668\n",
      "Calibration error = 5.98\n",
      "fold 5\n",
      "a = 0.37179847021630663 b = 0.11211291536648539\n",
      "Calibration error = 4.25\n",
      "LABEL = height\n",
      "fold 1\n",
      "a = 0.4281795169243614 b = -0.013087192326617182\n",
      "Calibration error = 6.29\n",
      "fold 2\n",
      "a = 0.44790723292249435 b = -0.010964036840463244\n",
      "Calibration error = 6.82\n",
      "fold 3\n",
      "a = 0.43426069842627407 b = -0.01159978543386171\n",
      "Calibration error = 6.69\n",
      "fold 4\n",
      "a = 0.4329507171733551 b = -0.012723568349657646\n",
      "Calibration error = 5.83\n",
      "fold 5\n",
      "a = 0.4184943276424946 b = -0.0090132310845966\n",
      "Calibration error = 6.91\n",
      "MODEL TYPE = ridge\n",
      "LABEL = impact site x\n",
      "fold 1\n",
      "a = 0.7848310356759235 b = 4.622299295939621\n",
      "Calibration error = 4.28\n",
      "fold 2\n",
      "a = 0.6327143286579869 b = 6.033555173640451\n",
      "Calibration error = 3.36\n",
      "fold 3\n",
      "a = 0.6110748027790012 b = 6.340247785394156\n",
      "Calibration error = 2.92\n",
      "fold 4\n",
      "a = 0.5609006180017027 b = 6.868051043298519\n",
      "Calibration error = 2.73\n",
      "fold 5\n",
      "a = 0.5417769694461612 b = 6.479345739585208\n",
      "Calibration error = 6.72\n",
      "LABEL = impact site y\n",
      "fold 1\n",
      "a = 0.46115738041886667 b = 8.940141125699164\n",
      "Calibration error = 4.29\n",
      "fold 2\n",
      "a = 0.8304046966659983 b = 6.113707758788321\n",
      "Calibration error = 3.78\n",
      "fold 3\n",
      "a = 0.8563175557240292 b = 5.927811704868034\n",
      "Calibration error = 3.67\n",
      "fold 4\n",
      "a = 0.6052524413707723 b = 7.890982096651475\n",
      "Calibration error = 3.21\n",
      "fold 5\n",
      "a = 0.825565361442397 b = 6.668847882159928\n",
      "Calibration error = 4.24\n",
      "LABEL = height\n",
      "fold 1\n",
      "a = 0.2811035118918983 b = 0.6938633149438078\n",
      "Calibration error = 3.14\n",
      "fold 2\n",
      "a = 0.3446116992996105 b = 0.6733182978654952\n",
      "Calibration error = 2.90\n",
      "fold 3\n",
      "a = 0.4126175667376652 b = 0.624881781588028\n",
      "Calibration error = 4.33\n",
      "fold 4\n",
      "a = 0.361690002208415 b = 0.6651253540667352\n",
      "Calibration error = 3.25\n",
      "fold 5\n",
      "a = 0.2685253576693232 b = 0.6935089742767052\n",
      "Calibration error = 5.21\n"
     ]
    }
   ],
   "source": [
    "'''Now we will evaluate the performance of the bagging models'''\n",
    "\n",
    "\n",
    "for model_type in model_types:\n",
    "    print(f'MODEL TYPE = {model_type}')\n",
    "    for label_to_predict in labels_to_predict:\n",
    "        print(f'LABEL = {label_to_predict}')\n",
    "        for num_models in num_models_list:\n",
    "            performance_data = []\n",
    "            for fold_no in range(1,6):\n",
    "                print(f'fold {fold_no}')\n",
    "\n",
    "                model_saving_folder = f'{model_folder}/{label_to_predict}/{model_type}/{num_models}_models/fold_{fold_no}'\n",
    "                results_saving_folder = f'{results_folder}/{label_to_predict}/{model_type}/{num_models}_models/fold_{fold_no}'\n",
    "                \n",
    "                test_features_path = Paper2_path + f'/5fold_datasets/{label_to_predict}/fold{fold_no}/test_features.csv'\n",
    "                test_labels_path = Paper2_path + f'/5fold_datasets/{label_to_predict}/fold{fold_no}/test_labels.csv'\n",
    "                train_features_path = Paper2_path + f'/5fold_datasets/{label_to_predict}/fold{fold_no}/train_features.csv'\n",
    "                train_labels_path = Paper2_path + f'/5fold_datasets/{label_to_predict}/fold{fold_no}/train_labels.csv'\n",
    "\n",
    "\n",
    "                features_to_keep = ast.literal_eval(all_features_to_keep[label_to_predict][model_type])\n",
    "                test_r2, test_ensemble_predictions, test_ensemble_uncertanties, test_labels = Get_predictions_and_uncertainty_with_bagging(test_features_path, test_labels_path, model_saving_folder, results_saving_folder, features_to_keep, label_to_predict, model_type)\n",
    "                train_r2, train_ensemble_predictions, train_ensemble_uncertanties, train_labels = Get_predictions_and_uncertainty_with_bagging(train_features_path, train_labels_path, model_saving_folder, results_saving_folder, features_to_keep, label_to_predict, model_type)\n",
    "\n",
    "\n",
    "                train_labels_arr = train_labels.to_numpy().T[0]\n",
    "                train_predictions_arr = np.array(train_ensemble_predictions)\n",
    "                test_labels_arr = test_labels.to_numpy().T[0]\n",
    "                test_predictions_arr = np.array(test_ensemble_predictions)\n",
    "                train_residuals = pd.Series(np.abs(train_labels_arr - train_predictions_arr))\n",
    "                test_residuals = pd.Series(np.abs(test_labels_arr - test_predictions_arr))\n",
    "\n",
    "                \n",
    "                '''getting calibration factors *** linear'''\n",
    "                cf = CorrectionFactors(train_residuals, pd.Series(train_ensemble_uncertanties))\n",
    "                a, b = cf.nll()\n",
    "                print(f'a = {a} b = {b}')\n",
    "                calibrated_train_uncertainties = pd.Series(a * np.array(train_ensemble_uncertanties) + b, name='train_model_errors')\n",
    "                calibrated_test_uncertainties = pd.Series(a * np.array(test_ensemble_uncertanties) + b, name='test_model_errors')\n",
    "                \n",
    "                \n",
    "                \n",
    "                '''getting calibration factors *** Nonlinear'''\n",
    "                # a, b = get_calibration_factors(train_residuals, train_ensemble_uncertanties)\n",
    "                # print(f'a = {a} b = {b}')\n",
    "                # calibrated_train_uncertainties = pd.Series(a * (train_ensemble_uncertanties**((b/2) + 1)), name='train_model_errors')\n",
    "                # calibrated_test_uncertainties = pd.Series(a * (test_ensemble_uncertanties**((b/2) + 1)), name='test_model_errors')\n",
    "\n",
    "                miscalibration_area, calibration_error = make_calibration_plots(model_type, test_predictions_arr, test_labels_arr, test_ensemble_uncertanties, results_saving_folder)\n",
    "\n",
    "                \n",
    "                blank_model_for_plot = SklearnModel('RandomForestRegressor')\n",
    "                mastml_RVE = Error()\n",
    "\n",
    "                # mastml_RVE.plot_real_vs_predicted_error_uncal_cal_overlay(savepath=results_saving_folder, \n",
    "                #                                                         model=blank_model_for_plot, \n",
    "                #                                                         data_type='train', \n",
    "                #                                                         model_errors=pd.Series(train_ensemble_uncertanties) ,\n",
    "                #                                                         model_errors_cal= calibrated_train_uncertainties,\n",
    "                #                                                         residuals= train_residuals, \n",
    "                #                                                         dataset_stdev=np.std(train_labels.to_numpy()), \n",
    "                #                                                         show_figure=False,\n",
    "                #                                                         well_sampled_number=0.025)\n",
    "                \n",
    "                \n",
    "                # mastml_RVE.plot_real_vs_predicted_error_uncal_cal_overlay(savepath=results_saving_folder, \n",
    "                #                                                         model=blank_model_for_plot, \n",
    "                #                                                         data_type='test', \n",
    "                #                                                         model_errors=pd.Series(test_ensemble_uncertanties) ,\n",
    "                #                                                         model_errors_cal= calibrated_test_uncertainties,\n",
    "                #                                                         residuals= test_residuals, \n",
    "                #                                                         dataset_stdev=np.std(train_labels.to_numpy()), \n",
    "                #                                                         show_figure=False,\n",
    "                #                                                         well_sampled_number=0.025)\n",
    "                '''using their library to make an rve plot'''\n",
    "                train_intercept, train_slope, CAL_train_intercept, CAL_train_slope, train_intercept, test_slope, CAL_test_intercept, CAL_test_slope = make_RVE_plots(label_to_predict, model_type, test_ensemble_predictions, test_ensemble_uncertanties, test_labels, train_ensemble_predictions, train_ensemble_uncertanties, train_labels, results_saving_folder, num_bins=15)\n",
    "                performance_data.append([15, fold_no, train_r2, test_r2, a, b, train_intercept, train_slope, CAL_train_intercept, CAL_train_slope, train_intercept, test_slope, CAL_test_intercept, CAL_test_slope, miscalibration_area, calibration_error])\n",
    "                \n",
    "            columns = ['num bins', 'fold_no', 'train R2', 'test R2',  'a', 'b', 'train_intercept', 'train_slope', 'CAL_train_intercept', 'CAL_train_slope', 'train_intercept', 'test_slope', 'CAL_test_intercept', 'CAL_test_slope', 'miscal_area', 'cal_error']\n",
    "            df = pd.DataFrame(columns=columns)\n",
    "            for row in performance_data:\n",
    "                df.loc[len(df)] = row\n",
    "            average_row = df.mean()\n",
    "            df = df.append(average_row, ignore_index=True)\n",
    "                \n",
    "            results_saving_folder = f'{results_folder}/{label_to_predict}/{model_type}/{num_models}_models'\n",
    "            df.to_csv(results_saving_folder + f'/{label_to_predict}_{model_type}_{num_models}results.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
